+-----------------+-------------------------+
|    Parameter    |          Value          |
+=================+=========================+
| Batch size      | 128                     |
+-----------------+-------------------------+
| Dataset         | NCI109                  |
+-----------------+-------------------------+
| Dropout ratio   | 0.5                     |
+-----------------+-------------------------+
| Epochs          | 10000                   |
+-----------------+-------------------------+
| Exp name        | NCI109_Hie              |
+-----------------+-------------------------+
| Gpu index       | 0                       |
+-----------------+-------------------------+
| Hid             | 128                     |
+-----------------+-------------------------+
| Lr              | 0.0005                  |
+-----------------+-------------------------+
| Model           | ASAPooling_Hierarchical |
+-----------------+-------------------------+
| Patience        | 40                      |
+-----------------+-------------------------+
| Pooling ratio   | 0.5                     |
+-----------------+-------------------------+
| Seed            | 16                      |
+-----------------+-------------------------+
| Test batch size | 1                       |
+-----------------+-------------------------+
| Weight decay    | 0.0001                  |
+-----------------+-------------------------+
Using GPU: 0
ASAPooling_Hierarchical(
  (conv1): GCNConv(38, 128)
  (conv2): GCNConv(128, 128)
  (conv3): GCNConv(128, 128)
  (pool): ASAPooling(128, ratio=0.5)
  (lin1): Linear(in_features=256, out_features=128, bias=True)
  (lin2): Linear(in_features=128, out_features=64, bias=True)
  (classifier): Linear(in_features=64, out_features=2, bias=True)
)
Model Parameter: 112966
Using Adam

Epoch #000, Train_Loss: [0.6946, 0.6934, 0.6934, 0.6931, 0.6932, 0.6919, 0.6919, 0.6936, 0.6944, 0.6960, 0.6924, 0.6928, 0.6930, 0.6972, 0.6917, 0.6934, 0.6923, 0.6931, 0.6931, 0.6923, 0.6924, 0.6932, 0.6934, 0.6949, 0.6928, 0.6922]
Val_Loss: 0.693082, Val_Acc: 0.490291
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #001, Train_Loss: [0.6942, 0.6931, 0.6926, 0.6938, 0.6922, 0.6933, 0.6928, 0.6933, 0.6927, 0.6920, 0.6928, 0.6938, 0.6946, 0.6934, 0.6924, 0.6929, 0.6926, 0.6941, 0.6918, 0.6927, 0.6927, 0.6930, 0.6916, 0.6932, 0.6925, 0.6916]
Val_Loss: 0.693159, Val_Acc: 0.487864

Epoch #002, Train_Loss: [0.6917, 0.6910, 0.6923, 0.6964, 0.6909, 0.6933, 0.6891, 0.6882, 0.6934, 0.6968, 0.6964, 0.6938, 0.6907, 0.6966, 0.6901, 0.6908, 0.6930, 0.6924, 0.6928, 0.6930, 0.6923, 0.6926, 0.6900, 0.6907, 0.6926, 0.6937]
Val_Loss: 0.692287, Val_Acc: 0.470874
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #003, Train_Loss: [0.6926, 0.6916, 0.6914, 0.6918, 0.6931, 0.6913, 0.6902, 0.6925, 0.6908, 0.6905, 0.6880, 0.6922, 0.6898, 0.6903, 0.6912, 0.6869, 0.6900, 0.6961, 0.6955, 0.6903, 0.6884, 0.6891, 0.6912, 0.6906, 0.6911, 0.6884]
Val_Loss: 0.689745, Val_Acc: 0.584951
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #004, Train_Loss: [0.6924, 0.6891, 0.6939, 0.6884, 0.6844, 0.6911, 0.6854, 0.6834, 0.6843, 0.6928, 0.6820, 0.6886, 0.6818, 0.6815, 0.6971, 0.6940, 0.6937, 0.6878, 0.6796, 0.6915, 0.6882, 0.6800, 0.6788, 0.6776, 0.6721, 0.6830]
Val_Loss: 0.680838, Val_Acc: 0.589806
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #005, Train_Loss: [0.6857, 0.6723, 0.6756, 0.6850, 0.6815, 0.6721, 0.6907, 0.7046, 0.6778, 0.6811, 0.6792, 0.6694, 0.6972, 0.6975, 0.6873, 0.6705, 0.6830, 0.6868, 0.6945, 0.6726, 0.6724, 0.6864, 0.6645, 0.7004, 0.6466, 0.6653]
Val_Loss: 0.691597, Val_Acc: 0.524272

Epoch #006, Train_Loss: [0.6822, 0.7091, 0.7033, 0.6844, 0.6895, 0.6809, 0.6675, 0.6732, 0.6583, 0.6792, 0.6926, 0.6962, 0.6568, 0.6690, 0.6726, 0.6689, 0.6877, 0.6815, 0.6848, 0.6579, 0.6557, 0.6548, 0.6711, 0.6949, 0.6863, 0.6812]
Val_Loss: 0.677541, Val_Acc: 0.570388
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #007, Train_Loss: [0.6655, 0.6692, 0.6814, 0.6689, 0.6621, 0.6594, 0.6717, 0.6846, 0.7019, 0.6786, 0.6572, 0.6653, 0.6717, 0.6819, 0.6699, 0.6757, 0.6610, 0.6390, 0.6707, 0.6911, 0.6559, 0.6974, 0.6301, 0.6553, 0.6524, 0.6675]
Val_Loss: 0.668951, Val_Acc: 0.597087
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #008, Train_Loss: [0.6608, 0.6583, 0.6919, 0.6760, 0.6638, 0.6895, 0.6717, 0.6557, 0.6694, 0.6986, 0.6613, 0.6553, 0.6340, 0.6488, 0.6609, 0.6477, 0.6945, 0.6621, 0.6560, 0.6544, 0.6514, 0.6474, 0.6672, 0.6478, 0.6386, 0.6674]
Val_Loss: 0.657051, Val_Acc: 0.631068
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #009, Train_Loss: [0.6681, 0.6286, 0.6427, 0.6451, 0.6304, 0.6617, 0.6494, 0.6271, 0.6684, 0.6476, 0.6479, 0.6822, 0.6803, 0.6350, 0.6666, 0.6306, 0.6380, 0.6339, 0.6619, 0.6895, 0.6401, 0.6853, 0.6288, 0.6693, 0.6278, 0.6651]
Val_Loss: 0.645674, Val_Acc: 0.633495
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #010, Train_Loss: [0.6290, 0.6181, 0.6583, 0.6330, 0.6359, 0.6473, 0.6572, 0.6119, 0.6263, 0.6453, 0.6093, 0.6305, 0.6393, 0.6166, 0.5807, 0.6584, 0.6176, 0.6927, 0.7125, 0.6670, 0.6532, 0.6143, 0.6729, 0.6525, 0.6359, 0.6581]
Val_Loss: 0.637912, Val_Acc: 0.614078
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #011, Train_Loss: [0.6249, 0.6508, 0.6193, 0.6727, 0.6423, 0.6499, 0.6303, 0.6221, 0.6253, 0.6337, 0.6647, 0.6393, 0.6507, 0.6508, 0.6332, 0.6302, 0.6164, 0.6044, 0.6493, 0.6282, 0.6082, 0.6263, 0.6080, 0.6252, 0.6598, 0.5936]
Val_Loss: 0.626770, Val_Acc: 0.648058
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #012, Train_Loss: [0.6450, 0.6039, 0.6277, 0.6629, 0.6061, 0.6372, 0.6499, 0.6168, 0.6271, 0.6601, 0.6067, 0.6346, 0.6277, 0.6397, 0.6434, 0.5826, 0.6274, 0.6026, 0.6626, 0.6413, 0.6310, 0.6740, 0.6209, 0.6005, 0.6208, 0.6315]
Val_Loss: 0.621666, Val_Acc: 0.645631
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #013, Train_Loss: [0.5707, 0.5970, 0.6468, 0.6477, 0.6146, 0.6402, 0.6224, 0.5697, 0.6280, 0.6364, 0.6257, 0.5890, 0.6156, 0.5839, 0.6148, 0.6177, 0.5898, 0.6767, 0.6285, 0.6245, 0.6596, 0.6605, 0.6336, 0.6241, 0.6296, 0.6123]
Val_Loss: 0.616111, Val_Acc: 0.650485
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #014, Train_Loss: [0.6445, 0.6584, 0.6034, 0.6337, 0.6385, 0.5955, 0.6038, 0.5845, 0.6126, 0.6102, 0.6671, 0.6136, 0.6055, 0.5988, 0.5679, 0.5917, 0.6405, 0.6471, 0.6915, 0.6348, 0.5227, 0.6272, 0.5871, 0.5677, 0.6976, 0.6371]
Val_Loss: 0.613037, Val_Acc: 0.667476
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #015, Train_Loss: [0.5637, 0.5741, 0.6034, 0.5934, 0.6304, 0.6119, 0.5866, 0.6391, 0.6270, 0.5946, 0.6202, 0.6014, 0.5998, 0.6455, 0.6282, 0.6123, 0.6193, 0.6057, 0.6055, 0.6216, 0.5944, 0.6263, 0.6019, 0.6568, 0.5979, 0.5774]
Val_Loss: 0.603049, Val_Acc: 0.667476
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #016, Train_Loss: [0.6557, 0.5964, 0.5883, 0.6201, 0.5911, 0.6088, 0.6164, 0.6203, 0.6050, 0.5645, 0.5817, 0.6216, 0.6036, 0.6149, 0.6072, 0.6488, 0.5825, 0.5880, 0.6160, 0.6283, 0.5992, 0.6211, 0.5850, 0.5976, 0.5900, 0.6388]
Val_Loss: 0.595802, Val_Acc: 0.677184
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #017, Train_Loss: [0.5735, 0.6285, 0.5765, 0.6572, 0.6762, 0.5517, 0.5687, 0.6568, 0.6139, 0.6041, 0.6624, 0.5937, 0.6493, 0.6118, 0.5686, 0.5808, 0.6069, 0.6450, 0.6762, 0.5732, 0.6422, 0.6527, 0.6291, 0.6378, 0.6241, 0.6466]
Val_Loss: 0.613388, Val_Acc: 0.652913

Epoch #018, Train_Loss: [0.6420, 0.6186, 0.5685, 0.6579, 0.5934, 0.6402, 0.6911, 0.6274, 0.5771, 0.6160, 0.6251, 0.6078, 0.5978, 0.5813, 0.5925, 0.5735, 0.6247, 0.5926, 0.6126, 0.5888, 0.5715, 0.6166, 0.5905, 0.5857, 0.6054, 0.6297]
Val_Loss: 0.585165, Val_Acc: 0.682039
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #019, Train_Loss: [0.6186, 0.6132, 0.5967, 0.6212, 0.6458, 0.6211, 0.5700, 0.5843, 0.6364, 0.6178, 0.5782, 0.6002, 0.5962, 0.5839, 0.5676, 0.6304, 0.5802, 0.6053, 0.5842, 0.5943, 0.6525, 0.6319, 0.5331, 0.5699, 0.6509, 0.6159]
Val_Loss: 0.606049, Val_Acc: 0.665049

Epoch #020, Train_Loss: [0.5899, 0.6288, 0.5760, 0.5883, 0.6070, 0.6125, 0.5870, 0.6352, 0.6176, 0.5700, 0.6480, 0.5805, 0.6251, 0.6144, 0.5986, 0.5738, 0.6093, 0.6470, 0.5905, 0.5287, 0.5637, 0.5829, 0.5694, 0.6119, 0.5281, 0.5934]
Val_Loss: 0.587369, Val_Acc: 0.689320

Epoch #021, Train_Loss: [0.5605, 0.5295, 0.5561, 0.6613, 0.5888, 0.6483, 0.6526, 0.6077, 0.6306, 0.5396, 0.6056, 0.6111, 0.6287, 0.5986, 0.5468, 0.6001, 0.6080, 0.5751, 0.6093, 0.6624, 0.5730, 0.5061, 0.6336, 0.6078, 0.6014, 0.6525]
Val_Loss: 0.639285, Val_Acc: 0.626214

Epoch #022, Train_Loss: [0.6153, 0.6356, 0.6041, 0.6098, 0.5714, 0.6103, 0.6196, 0.5888, 0.6149, 0.5982, 0.6150, 0.5709, 0.6046, 0.5977, 0.5805, 0.6329, 0.5591, 0.5795, 0.5746, 0.5800, 0.5951, 0.5736, 0.6156, 0.5899, 0.5837, 0.6913]
Val_Loss: 0.578537, Val_Acc: 0.691748
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #023, Train_Loss: [0.5816, 0.5491, 0.6243, 0.5365, 0.5953, 0.5234, 0.6125, 0.6531, 0.5709, 0.6281, 0.5517, 0.5616, 0.5833, 0.6076, 0.4940, 0.5692, 0.6198, 0.6510, 0.5043, 0.6050, 0.5607, 0.6221, 0.6334, 0.6038, 0.6452, 0.6073]
Val_Loss: 0.582255, Val_Acc: 0.699029

Epoch #024, Train_Loss: [0.5507, 0.6088, 0.5838, 0.6385, 0.5968, 0.5725, 0.6339, 0.6151, 0.5503, 0.5822, 0.5553, 0.5721, 0.5394, 0.5643, 0.5552, 0.6311, 0.5856, 0.5418, 0.6054, 0.6175, 0.6289, 0.6109, 0.6272, 0.6471, 0.6094, 0.5300]
Val_Loss: 0.579415, Val_Acc: 0.684466

Epoch #025, Train_Loss: [0.5690, 0.5830, 0.5948, 0.6085, 0.6245, 0.5596, 0.6251, 0.5580, 0.5487, 0.5437, 0.5653, 0.5985, 0.6516, 0.6149, 0.5750, 0.5938, 0.5252, 0.6125, 0.5455, 0.5638, 0.5624, 0.6185, 0.6136, 0.6076, 0.5959, 0.6342]
Val_Loss: 0.579297, Val_Acc: 0.706311

Epoch #026, Train_Loss: [0.5688, 0.5931, 0.6000, 0.5953, 0.5767, 0.6520, 0.6227, 0.6324, 0.6197, 0.5698, 0.6059, 0.6322, 0.5902, 0.6277, 0.5894, 0.5229, 0.5619, 0.5848, 0.5689, 0.5447, 0.5818, 0.5688, 0.5236, 0.5850, 0.5447, 0.5572]
Val_Loss: 0.591733, Val_Acc: 0.674757

Epoch #027, Train_Loss: [0.6157, 0.5584, 0.6468, 0.5506, 0.5549, 0.5754, 0.6024, 0.5366, 0.4999, 0.5829, 0.6611, 0.6013, 0.5951, 0.5934, 0.6643, 0.5698, 0.5357, 0.5381, 0.6329, 0.5543, 0.6063, 0.6113, 0.5886, 0.6177, 0.6293, 0.5031]
Val_Loss: 0.593680, Val_Acc: 0.682039

Epoch #028, Train_Loss: [0.6487, 0.5808, 0.5978, 0.5064, 0.6122, 0.5442, 0.5515, 0.6171, 0.6179, 0.6136, 0.6089, 0.5937, 0.6001, 0.5436, 0.5888, 0.5651, 0.5420, 0.4994, 0.5852, 0.5799, 0.5725, 0.5828, 0.5278, 0.5664, 0.5648, 0.5845]
Val_Loss: 0.586820, Val_Acc: 0.703883

Epoch #029, Train_Loss: [0.6214, 0.5888, 0.6077, 0.5545, 0.5891, 0.5933, 0.6265, 0.5706, 0.6424, 0.6018, 0.5032, 0.6208, 0.5663, 0.6007, 0.5784, 0.6160, 0.5637, 0.6511, 0.6374, 0.5819, 0.5339, 0.5834, 0.5260, 0.5369, 0.5478, 0.6492]
Val_Loss: 0.591220, Val_Acc: 0.696602

Epoch #030, Train_Loss: [0.5623, 0.6142, 0.5049, 0.5916, 0.6708, 0.6656, 0.6266, 0.5183, 0.5333, 0.5585, 0.6097, 0.6496, 0.6288, 0.5175, 0.6491, 0.5520, 0.5634, 0.5912, 0.5904, 0.5699, 0.5424, 0.5711, 0.5427, 0.5726, 0.5479, 0.5816]
Val_Loss: 0.583209, Val_Acc: 0.689320

Epoch #031, Train_Loss: [0.5529, 0.5768, 0.5655, 0.6072, 0.5403, 0.6448, 0.5410, 0.6266, 0.5625, 0.5155, 0.5302, 0.5229, 0.5834, 0.5432, 0.5964, 0.5506, 0.5435, 0.6216, 0.6266, 0.5471, 0.6191, 0.6103, 0.6091, 0.5740, 0.5066, 0.5162]
Val_Loss: 0.585008, Val_Acc: 0.686893

Epoch #032, Train_Loss: [0.5472, 0.6156, 0.5846, 0.5925, 0.5139, 0.5619, 0.6722, 0.6026, 0.5502, 0.6341, 0.5318, 0.5387, 0.6042, 0.5580, 0.5528, 0.5565, 0.5111, 0.5955, 0.5587, 0.5680, 0.5641, 0.5781, 0.5641, 0.6012, 0.6481, 0.5325]
Val_Loss: 0.582691, Val_Acc: 0.701456

Epoch #033, Train_Loss: [0.5901, 0.6100, 0.5668, 0.6091, 0.5908, 0.6453, 0.5264, 0.5989, 0.5692, 0.5593, 0.5460, 0.5657, 0.5850, 0.5873, 0.5825, 0.5520, 0.5415, 0.5875, 0.5087, 0.5141, 0.5939, 0.6264, 0.5813, 0.6348, 0.5663, 0.6980]
Val_Loss: 0.603168, Val_Acc: 0.667476

Epoch #034, Train_Loss: [0.6389, 0.5892, 0.5076, 0.5588, 0.5774, 0.6528, 0.5580, 0.6074, 0.5863, 0.5808, 0.5384, 0.5650, 0.5672, 0.6369, 0.6157, 0.6052, 0.5577, 0.5109, 0.5697, 0.6162, 0.5487, 0.5726, 0.5370, 0.5312, 0.5068, 0.5647]
Val_Loss: 0.588796, Val_Acc: 0.669903

Epoch #035, Train_Loss: [0.4956, 0.5960, 0.5402, 0.5840, 0.5540, 0.5207, 0.6456, 0.5654, 0.5533, 0.5688, 0.5760, 0.5936, 0.6002, 0.5398, 0.6320, 0.5218, 0.5649, 0.5887, 0.6140, 0.5296, 0.5587, 0.5841, 0.5615, 0.6766, 0.5706, 0.5926]
Val_Loss: 0.575011, Val_Acc: 0.696602
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #036, Train_Loss: [0.5891, 0.5556, 0.5327, 0.6573, 0.5587, 0.6622, 0.5603, 0.5812, 0.5755, 0.6165, 0.5502, 0.5853, 0.5540, 0.5604, 0.5762, 0.5251, 0.5594, 0.5788, 0.5773, 0.5375, 0.4991, 0.5399, 0.6188, 0.6524, 0.5537, 0.4633]
Val_Loss: 0.569488, Val_Acc: 0.703883
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #037, Train_Loss: [0.5411, 0.5481, 0.6248, 0.5677, 0.5970, 0.5663, 0.5589, 0.6223, 0.6175, 0.5516, 0.5372, 0.5449, 0.5618, 0.5629, 0.5476, 0.6377, 0.5120, 0.5815, 0.5905, 0.5754, 0.5599, 0.6463, 0.5600, 0.5555, 0.5587, 0.5681]
Val_Loss: 0.578679, Val_Acc: 0.694175

Epoch #038, Train_Loss: [0.5411, 0.5576, 0.5125, 0.6268, 0.6174, 0.6115, 0.6159, 0.5764, 0.5148, 0.5740, 0.4927, 0.6204, 0.5922, 0.6366, 0.5435, 0.5968, 0.5864, 0.5021, 0.5979, 0.5103, 0.6071, 0.5614, 0.6016, 0.5684, 0.6045, 0.5880]
Val_Loss: 0.578152, Val_Acc: 0.689320

Epoch #039, Train_Loss: [0.5668, 0.5557, 0.6237, 0.6181, 0.5487, 0.5517, 0.5651, 0.5367, 0.5833, 0.5353, 0.5929, 0.5756, 0.6471, 0.5568, 0.5946, 0.6027, 0.5486, 0.5387, 0.5446, 0.5983, 0.5469, 0.5035, 0.5469, 0.5559, 0.5819, 0.5294]
Val_Loss: 0.578220, Val_Acc: 0.686893

Epoch #040, Train_Loss: [0.5532, 0.5444, 0.5725, 0.5899, 0.5417, 0.5097, 0.5533, 0.6067, 0.5824, 0.5934, 0.6251, 0.5237, 0.5809, 0.4826, 0.5169, 0.6021, 0.5097, 0.5288, 0.5501, 0.6163, 0.5931, 0.5379, 0.5845, 0.5066, 0.5662, 0.5479]
Val_Loss: 0.580158, Val_Acc: 0.699029

Epoch #041, Train_Loss: [0.5204, 0.6547, 0.4911, 0.5767, 0.5454, 0.5806, 0.5552, 0.5095, 0.5730, 0.6117, 0.5516, 0.5446, 0.5402, 0.5206, 0.5778, 0.5419, 0.5233, 0.5475, 0.5686, 0.5855, 0.5244, 0.5850, 0.5176, 0.5783, 0.6225, 0.5748]
Val_Loss: 0.565484, Val_Acc: 0.713592
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #042, Train_Loss: [0.5441, 0.5347, 0.5708, 0.6444, 0.5299, 0.5171, 0.6260, 0.4925, 0.5879, 0.6370, 0.5385, 0.6460, 0.5032, 0.5749, 0.5489, 0.5587, 0.5702, 0.5485, 0.5877, 0.5086, 0.5801, 0.5453, 0.5643, 0.5203, 0.5355, 0.5456]
Val_Loss: 0.563282, Val_Acc: 0.708738
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #043, Train_Loss: [0.5384, 0.5037, 0.6360, 0.5323, 0.5733, 0.5490, 0.5866, 0.5172, 0.5712, 0.5266, 0.5858, 0.6004, 0.5602, 0.6539, 0.4881, 0.5765, 0.5932, 0.5168, 0.5837, 0.4950, 0.5122, 0.6047, 0.6089, 0.4786, 0.5195, 0.5099]
Val_Loss: 0.566561, Val_Acc: 0.706311

Epoch #044, Train_Loss: [0.5427, 0.5868, 0.5468, 0.5164, 0.5579, 0.5320, 0.5776, 0.5060, 0.5323, 0.5915, 0.5935, 0.5477, 0.5847, 0.5525, 0.5249, 0.5662, 0.5371, 0.6109, 0.5622, 0.5870, 0.6081, 0.5141, 0.5239, 0.5347, 0.5175, 0.5250]
Val_Loss: 0.577684, Val_Acc: 0.677184

Epoch #045, Train_Loss: [0.5412, 0.5524, 0.5120, 0.4900, 0.5869, 0.5641, 0.5077, 0.6118, 0.5071, 0.5899, 0.5430, 0.5701, 0.5204, 0.5389, 0.5082, 0.5436, 0.5220, 0.5555, 0.4971, 0.5544, 0.6438, 0.5701, 0.5904, 0.5501, 0.5887, 0.5420]
Val_Loss: 0.568027, Val_Acc: 0.720874

Epoch #046, Train_Loss: [0.5612, 0.5001, 0.5450, 0.5068, 0.5746, 0.6154, 0.5182, 0.5551, 0.5802, 0.5229, 0.5799, 0.5387, 0.4895, 0.5696, 0.6033, 0.5496, 0.5222, 0.5399, 0.4866, 0.5930, 0.5163, 0.6041, 0.5137, 0.4993, 0.6464, 0.4934]
Val_Loss: 0.602178, Val_Acc: 0.667476

Epoch #047, Train_Loss: [0.5408, 0.5157, 0.5137, 0.5439, 0.5959, 0.5819, 0.5344, 0.5534, 0.5447, 0.5574, 0.5417, 0.6062, 0.5740, 0.5356, 0.6013, 0.5841, 0.5805, 0.5093, 0.5320, 0.4900, 0.5438, 0.5143, 0.5997, 0.6543, 0.5533, 0.4536]
Val_Loss: 0.562693, Val_Acc: 0.708738
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #048, Train_Loss: [0.5166, 0.5838, 0.5256, 0.4628, 0.5270, 0.5507, 0.5808, 0.5703, 0.5786, 0.5490, 0.5294, 0.5891, 0.5323, 0.4477, 0.5717, 0.6225, 0.4642, 0.5099, 0.5724, 0.4977, 0.5582, 0.5325, 0.5537, 0.6018, 0.6526, 0.4952]
Val_Loss: 0.557725, Val_Acc: 0.713592
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #049, Train_Loss: [0.5462, 0.5735, 0.5516, 0.5855, 0.5358, 0.5093, 0.5481, 0.5579, 0.5625, 0.5959, 0.4667, 0.5036, 0.5338, 0.5074, 0.5859, 0.6002, 0.5404, 0.5203, 0.6216, 0.5267, 0.5582, 0.5318, 0.5917, 0.5233, 0.5524, 0.5076]
Val_Loss: 0.578849, Val_Acc: 0.686893

Epoch #050, Train_Loss: [0.5828, 0.5113, 0.5179, 0.5641, 0.5456, 0.4498, 0.4547, 0.5102, 0.5039, 0.5876, 0.5045, 0.6258, 0.6266, 0.5431, 0.5429, 0.5446, 0.4979, 0.5740, 0.5055, 0.5996, 0.5539, 0.6361, 0.4898, 0.4943, 0.5115, 0.6360]
Val_Loss: 0.565022, Val_Acc: 0.716019

Epoch #051, Train_Loss: [0.5414, 0.5800, 0.4605, 0.5965, 0.5101, 0.5464, 0.5943, 0.5348, 0.6392, 0.5931, 0.5432, 0.4706, 0.5416, 0.5277, 0.5554, 0.6021, 0.5484, 0.5282, 0.4920, 0.5239, 0.4723, 0.5579, 0.5566, 0.5182, 0.5058, 0.5432]
Val_Loss: 0.552675, Val_Acc: 0.720874
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #052, Train_Loss: [0.5630, 0.5242, 0.6294, 0.5332, 0.5171, 0.5222, 0.5921, 0.4969, 0.5371, 0.5707, 0.5768, 0.5131, 0.4917, 0.4913, 0.4788, 0.5109, 0.5485, 0.5168, 0.5852, 0.5452, 0.4688, 0.5511, 0.5127, 0.5451, 0.5864, 0.6132]
Val_Loss: 0.552068, Val_Acc: 0.745146
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #053, Train_Loss: [0.5225, 0.5878, 0.5781, 0.5256, 0.5656, 0.4650, 0.5392, 0.5009, 0.5140, 0.5462, 0.5103, 0.5344, 0.5580, 0.5002, 0.5591, 0.5312, 0.6005, 0.5190, 0.5455, 0.6094, 0.5486, 0.5362, 0.6174, 0.5531, 0.5442, 0.5223]
Val_Loss: 0.546640, Val_Acc: 0.742718
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #054, Train_Loss: [0.5330, 0.5710, 0.5395, 0.5281, 0.5558, 0.5986, 0.4911, 0.4926, 0.5524, 0.5581, 0.5216, 0.5493, 0.4904, 0.5391, 0.5146, 0.5284, 0.5237, 0.5802, 0.5466, 0.5225, 0.5325, 0.5986, 0.5150, 0.4497, 0.5488, 0.5183]
Val_Loss: 0.543782, Val_Acc: 0.720874
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #055, Train_Loss: [0.5172, 0.5295, 0.4973, 0.5397, 0.5654, 0.5727, 0.5326, 0.6015, 0.5316, 0.5722, 0.4987, 0.5514, 0.5320, 0.4879, 0.4741, 0.5572, 0.4899, 0.5118, 0.5034, 0.4835, 0.6014, 0.5733, 0.5547, 0.5095, 0.5823, 0.5802]
Val_Loss: 0.541564, Val_Acc: 0.711165
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #056, Train_Loss: [0.4751, 0.5260, 0.5674, 0.5150, 0.5697, 0.5136, 0.5434, 0.5330, 0.6095, 0.5744, 0.5227, 0.5343, 0.5311, 0.5763, 0.5723, 0.4673, 0.5254, 0.4898, 0.5746, 0.5104, 0.5539, 0.5017, 0.5471, 0.4830, 0.6123, 0.4740]
Val_Loss: 0.547001, Val_Acc: 0.718447

Epoch #057, Train_Loss: [0.5047, 0.4786, 0.5319, 0.5337, 0.5873, 0.4451, 0.5798, 0.4960, 0.5226, 0.5347, 0.5096, 0.5734, 0.6184, 0.4975, 0.5434, 0.5642, 0.5601, 0.5243, 0.5485, 0.4998, 0.5556, 0.5863, 0.5337, 0.5168, 0.4722, 0.5430]
Val_Loss: 0.555214, Val_Acc: 0.735437

Epoch #058, Train_Loss: [0.5690, 0.5505, 0.5058, 0.5713, 0.5328, 0.5999, 0.5241, 0.5241, 0.5206, 0.5730, 0.5147, 0.5129, 0.5192, 0.5743, 0.5455, 0.5273, 0.5360, 0.5647, 0.4920, 0.5352, 0.5494, 0.5156, 0.5316, 0.5580, 0.5075, 0.4917]
Val_Loss: 0.583541, Val_Acc: 0.684466

Epoch #059, Train_Loss: [0.5658, 0.5351, 0.5588, 0.5668, 0.5343, 0.4912, 0.6056, 0.5322, 0.5543, 0.4862, 0.5838, 0.4919, 0.5660, 0.5492, 0.5447, 0.5005, 0.5401, 0.5151, 0.4900, 0.5420, 0.5366, 0.5107, 0.4770, 0.5545, 0.4546, 0.6285]
Val_Loss: 0.543902, Val_Acc: 0.742718

Epoch #060, Train_Loss: [0.5755, 0.5962, 0.5122, 0.4927, 0.5174, 0.5247, 0.4979, 0.5221, 0.5407, 0.5050, 0.5649, 0.4699, 0.5711, 0.5368, 0.5561, 0.4701, 0.5262, 0.5133, 0.4688, 0.5228, 0.6513, 0.4900, 0.5839, 0.5712, 0.5071, 0.5293]
Val_Loss: 0.542667, Val_Acc: 0.733010

Epoch #061, Train_Loss: [0.4937, 0.5326, 0.5199, 0.4662, 0.5715, 0.6300, 0.5240, 0.5014, 0.5142, 0.5493, 0.5376, 0.4970, 0.5165, 0.4731, 0.5649, 0.5316, 0.5509, 0.5756, 0.4805, 0.5021, 0.5454, 0.5621, 0.5555, 0.5706, 0.5146, 0.4478]
Val_Loss: 0.534136, Val_Acc: 0.728155
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #062, Train_Loss: [0.5462, 0.5531, 0.4730, 0.5010, 0.5431, 0.6133, 0.5321, 0.4560, 0.5373, 0.4572, 0.4701, 0.4366, 0.5217, 0.5505, 0.5519, 0.6296, 0.5594, 0.5509, 0.5425, 0.5396, 0.5237, 0.5271, 0.5297, 0.4903, 0.5448, 0.5697]
Val_Loss: 0.548974, Val_Acc: 0.706311

Epoch #063, Train_Loss: [0.5247, 0.5220, 0.4833, 0.4714, 0.5196, 0.5202, 0.5495, 0.4973, 0.4879, 0.4658, 0.6225, 0.5287, 0.5007, 0.5269, 0.6099, 0.5384, 0.5399, 0.5851, 0.5997, 0.4735, 0.5273, 0.6233, 0.5229, 0.5529, 0.4849, 0.5192]
Val_Loss: 0.535072, Val_Acc: 0.754854

Epoch #064, Train_Loss: [0.4693, 0.5249, 0.5041, 0.6000, 0.5199, 0.5300, 0.5425, 0.5995, 0.5359, 0.5411, 0.5833, 0.5890, 0.5472, 0.4444, 0.5476, 0.5122, 0.5161, 0.5784, 0.5240, 0.5541, 0.5432, 0.5522, 0.5506, 0.6164, 0.6256, 0.5172]
Val_Loss: 0.532072, Val_Acc: 0.737864
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #065, Train_Loss: [0.5036, 0.5929, 0.5361, 0.4986, 0.4799, 0.5248, 0.5121, 0.5473, 0.6072, 0.4875, 0.5307, 0.4805, 0.5161, 0.5952, 0.5026, 0.4995, 0.6170, 0.6054, 0.5884, 0.5031, 0.4926, 0.5609, 0.5127, 0.5428, 0.5217, 0.5609]
Val_Loss: 0.532799, Val_Acc: 0.757282

Epoch #066, Train_Loss: [0.5125, 0.4745, 0.5162, 0.5532, 0.4402, 0.5627, 0.5640, 0.5671, 0.4788, 0.4932, 0.4355, 0.5899, 0.4898, 0.5576, 0.4915, 0.5058, 0.5056, 0.4705, 0.4606, 0.5221, 0.5074, 0.5978, 0.5538, 0.4961, 0.6093, 0.5243]
Val_Loss: 0.525547, Val_Acc: 0.757282
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #067, Train_Loss: [0.4905, 0.4981, 0.5296, 0.5221, 0.5708, 0.5242, 0.5436, 0.4827, 0.4633, 0.4845, 0.5748, 0.4786, 0.5169, 0.5230, 0.5239, 0.5682, 0.5959, 0.5281, 0.4703, 0.5796, 0.5205, 0.5235, 0.4529, 0.5870, 0.5319, 0.5911]
Val_Loss: 0.535296, Val_Acc: 0.742718

Epoch #068, Train_Loss: [0.5818, 0.5022, 0.5207, 0.5037, 0.4873, 0.5310, 0.5351, 0.5406, 0.5423, 0.5131, 0.5761, 0.5337, 0.4779, 0.5319, 0.5017, 0.5172, 0.5631, 0.5071, 0.4728, 0.6370, 0.4467, 0.5061, 0.5692, 0.5110, 0.4170, 0.5131]
Val_Loss: 0.533996, Val_Acc: 0.735437

Epoch #069, Train_Loss: [0.4907, 0.6405, 0.5311, 0.4368, 0.4811, 0.5360, 0.5092, 0.5488, 0.4826, 0.5452, 0.4686, 0.4933, 0.4728, 0.4923, 0.6040, 0.5011, 0.5120, 0.5877, 0.5656, 0.5007, 0.5372, 0.5124, 0.5892, 0.4793, 0.5070, 0.4802]
Val_Loss: 0.529261, Val_Acc: 0.725728

Epoch #070, Train_Loss: [0.4749, 0.5144, 0.4754, 0.5130, 0.5562, 0.4769, 0.5668, 0.4738, 0.4525, 0.5262, 0.6294, 0.5119, 0.5213, 0.5753, 0.5845, 0.5106, 0.4453, 0.5028, 0.5440, 0.5282, 0.5382, 0.5866, 0.4671, 0.4964, 0.5383, 0.4407]
Val_Loss: 0.536787, Val_Acc: 0.728155

Epoch #071, Train_Loss: [0.4332, 0.5345, 0.4335, 0.5974, 0.4310, 0.5859, 0.4753, 0.4826, 0.5527, 0.4950, 0.5664, 0.5403, 0.5404, 0.4712, 0.5100, 0.5468, 0.5053, 0.5500, 0.4879, 0.6152, 0.6096, 0.5796, 0.4545, 0.5088, 0.4917, 0.4864]
Val_Loss: 0.529655, Val_Acc: 0.740291

Epoch #072, Train_Loss: [0.5949, 0.4953, 0.4712, 0.4985, 0.4815, 0.5169, 0.5552, 0.5480, 0.5180, 0.4959, 0.5004, 0.5152, 0.5314, 0.5386, 0.4770, 0.5268, 0.5052, 0.5102, 0.5785, 0.5417, 0.5693, 0.5701, 0.4178, 0.5333, 0.4788, 0.5475]
Val_Loss: 0.525720, Val_Acc: 0.740291

Epoch #073, Train_Loss: [0.4906, 0.5870, 0.5592, 0.5692, 0.5592, 0.4381, 0.4972, 0.5555, 0.4916, 0.5765, 0.4892, 0.4795, 0.5412, 0.4973, 0.4679, 0.4607, 0.4552, 0.5458, 0.4455, 0.4207, 0.5418, 0.5034, 0.4979, 0.5591, 0.6503, 0.5928]
Val_Loss: 0.527726, Val_Acc: 0.752427

Epoch #074, Train_Loss: [0.4483, 0.5113, 0.5188, 0.4756, 0.5769, 0.5554, 0.5546, 0.5588, 0.5658, 0.4784, 0.4863, 0.5675, 0.4670, 0.5223, 0.5257, 0.5013, 0.4693, 0.4128, 0.4395, 0.5001, 0.5064, 0.5530, 0.5513, 0.5068, 0.5591, 0.6062]
Val_Loss: 0.540268, Val_Acc: 0.730583

Epoch #075, Train_Loss: [0.5107, 0.4928, 0.5227, 0.5230, 0.5136, 0.5193, 0.5207, 0.5438, 0.5133, 0.5008, 0.5012, 0.5255, 0.5662, 0.5470, 0.5236, 0.5253, 0.6425, 0.4597, 0.4996, 0.4650, 0.4873, 0.4784, 0.5179, 0.4762, 0.5530, 0.5290]
Val_Loss: 0.525555, Val_Acc: 0.745146

Epoch #076, Train_Loss: [0.4992, 0.4380, 0.5446, 0.5612, 0.4860, 0.5332, 0.5959, 0.5278, 0.5327, 0.4885, 0.5218, 0.4669, 0.5149, 0.5807, 0.4649, 0.5355, 0.4668, 0.5363, 0.4710, 0.5613, 0.5500, 0.4399, 0.5494, 0.5425, 0.5202, 0.5084]
Val_Loss: 0.563338, Val_Acc: 0.733010

Epoch #077, Train_Loss: [0.5254, 0.5254, 0.4860, 0.5655, 0.4743, 0.5246, 0.5505, 0.5219, 0.5517, 0.4572, 0.5414, 0.5543, 0.4987, 0.4328, 0.5680, 0.5069, 0.5261, 0.4992, 0.5512, 0.4692, 0.4709, 0.5449, 0.5674, 0.5193, 0.4255, 0.5792]
Val_Loss: 0.524785, Val_Acc: 0.737864
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #078, Train_Loss: [0.4837, 0.5602, 0.4368, 0.5464, 0.5661, 0.5535, 0.4671, 0.6157, 0.5414, 0.4516, 0.5234, 0.5537, 0.4885, 0.5174, 0.5002, 0.5135, 0.5220, 0.5249, 0.5079, 0.5355, 0.4194, 0.4578, 0.4611, 0.4739, 0.5651, 0.5211]
Val_Loss: 0.538827, Val_Acc: 0.728155

Epoch #079, Train_Loss: [0.5680, 0.4405, 0.4805, 0.4824, 0.4876, 0.4667, 0.4833, 0.5387, 0.5400, 0.4983, 0.5173, 0.5529, 0.4911, 0.4663, 0.5584, 0.5464, 0.5056, 0.6005, 0.4833, 0.4749, 0.4702, 0.5859, 0.5108, 0.4799, 0.5068, 0.5534]
Val_Loss: 0.535962, Val_Acc: 0.718447

Epoch #080, Train_Loss: [0.5171, 0.5004, 0.5016, 0.4950, 0.5151, 0.4741, 0.4753, 0.4367, 0.5169, 0.5512, 0.4953, 0.6260, 0.5281, 0.4315, 0.4562, 0.5279, 0.4882, 0.5823, 0.5222, 0.5048, 0.4590, 0.6109, 0.5633, 0.5023, 0.5183, 0.5638]
Val_Loss: 0.536518, Val_Acc: 0.733010

Epoch #081, Train_Loss: [0.4442, 0.4693, 0.4889, 0.4982, 0.5604, 0.5275, 0.5229, 0.5769, 0.5188, 0.5568, 0.5563, 0.5175, 0.4907, 0.4994, 0.4601, 0.5673, 0.5112, 0.4994, 0.4983, 0.4911, 0.6414, 0.4960, 0.4520, 0.5414, 0.5107, 0.4331]
Val_Loss: 0.520852, Val_Acc: 0.745146
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #082, Train_Loss: [0.4825, 0.4907, 0.5624, 0.5302, 0.5034, 0.5226, 0.5555, 0.5057, 0.4607, 0.4168, 0.4598, 0.4630, 0.5691, 0.5312, 0.5526, 0.4729, 0.5101, 0.4713, 0.4934, 0.4967, 0.4962, 0.5163, 0.4376, 0.5326, 0.5456, 0.4855]
Val_Loss: 0.523954, Val_Acc: 0.735437

Epoch #083, Train_Loss: [0.4597, 0.5793, 0.5863, 0.5229, 0.5865, 0.5310, 0.5520, 0.4661, 0.5114, 0.5218, 0.5204, 0.5016, 0.5520, 0.4453, 0.5224, 0.4590, 0.5274, 0.5188, 0.5108, 0.4931, 0.5111, 0.4564, 0.5719, 0.4764, 0.4938, 0.4326]
Val_Loss: 0.522422, Val_Acc: 0.740291

Epoch #084, Train_Loss: [0.4328, 0.5790, 0.4420, 0.5577, 0.4801, 0.4121, 0.4911, 0.4859, 0.4794, 0.5293, 0.5196, 0.5374, 0.4217, 0.4576, 0.4908, 0.5415, 0.5811, 0.5453, 0.5211, 0.5358, 0.5225, 0.4947, 0.5479, 0.5571, 0.5785, 0.5330]
Val_Loss: 0.513680, Val_Acc: 0.757282
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #085, Train_Loss: [0.5452, 0.5410, 0.4996, 0.5427, 0.5140, 0.4646, 0.5291, 0.4828, 0.5012, 0.4853, 0.5273, 0.4681, 0.5225, 0.4659, 0.5262, 0.4370, 0.5471, 0.3929, 0.4805, 0.4789, 0.5870, 0.5760, 0.4999, 0.5135, 0.5299, 0.5153]
Val_Loss: 0.521476, Val_Acc: 0.742718

Epoch #086, Train_Loss: [0.5401, 0.5020, 0.4720, 0.5319, 0.5567, 0.5305, 0.5670, 0.4802, 0.5127, 0.4455, 0.4199, 0.4925, 0.5269, 0.4890, 0.4763, 0.4981, 0.5983, 0.5285, 0.4556, 0.5650, 0.4693, 0.4866, 0.4839, 0.5025, 0.5028, 0.5387]
Val_Loss: 0.541293, Val_Acc: 0.718447

Epoch #087, Train_Loss: [0.5350, 0.6101, 0.4939, 0.4951, 0.5655, 0.4861, 0.4704, 0.4584, 0.6033, 0.5611, 0.4981, 0.4467, 0.4932, 0.5917, 0.4615, 0.5548, 0.5473, 0.4754, 0.4967, 0.5306, 0.4657, 0.4158, 0.5623, 0.5194, 0.4837, 0.4635]
Val_Loss: 0.521717, Val_Acc: 0.733010

Epoch #088, Train_Loss: [0.5736, 0.4568, 0.5015, 0.5014, 0.5231, 0.5643, 0.4483, 0.5010, 0.5489, 0.4937, 0.5307, 0.4627, 0.5334, 0.5609, 0.4124, 0.5254, 0.4470, 0.4666, 0.4779, 0.4266, 0.5114, 0.5677, 0.4309, 0.4223, 0.5236, 0.5063]
Val_Loss: 0.529789, Val_Acc: 0.735437

Epoch #089, Train_Loss: [0.4835, 0.5475, 0.4899, 0.5214, 0.4696, 0.5119, 0.5462, 0.4887, 0.4857, 0.5612, 0.4662, 0.5079, 0.4734, 0.4412, 0.5066, 0.5468, 0.4470, 0.5336, 0.4661, 0.5691, 0.5068, 0.5369, 0.4787, 0.5101, 0.4964, 0.4494]
Val_Loss: 0.536546, Val_Acc: 0.752427

Epoch #090, Train_Loss: [0.5532, 0.5320, 0.5054, 0.6021, 0.4657, 0.4388, 0.5005, 0.4314, 0.4652, 0.5086, 0.5781, 0.5355, 0.5551, 0.4750, 0.4881, 0.4825, 0.4706, 0.4895, 0.4699, 0.5125, 0.5029, 0.4933, 0.4157, 0.4823, 0.5258, 0.4692]
Val_Loss: 0.535099, Val_Acc: 0.730583

Epoch #091, Train_Loss: [0.4769, 0.5165, 0.4092, 0.4779, 0.5777, 0.4759, 0.4678, 0.5293, 0.4571, 0.4952, 0.5610, 0.4848, 0.4882, 0.5784, 0.5041, 0.5555, 0.4875, 0.5172, 0.4523, 0.4343, 0.4619, 0.5530, 0.4298, 0.4823, 0.5744, 0.4590]
Val_Loss: 0.521230, Val_Acc: 0.752427

Epoch #092, Train_Loss: [0.4839, 0.4803, 0.4407, 0.4940, 0.5117, 0.5413, 0.4984, 0.4363, 0.5069, 0.5014, 0.5174, 0.5410, 0.4167, 0.4947, 0.4542, 0.4855, 0.5980, 0.5053, 0.4825, 0.5238, 0.4333, 0.5261, 0.4838, 0.4796, 0.4451, 0.4789]
Val_Loss: 0.529625, Val_Acc: 0.742718

Epoch #093, Train_Loss: [0.4444, 0.4463, 0.5198, 0.5378, 0.5467, 0.4169, 0.5719, 0.4778, 0.4436, 0.5077, 0.5286, 0.4713, 0.5030, 0.5225, 0.4817, 0.4605, 0.4656, 0.5454, 0.4585, 0.5290, 0.4339, 0.4706, 0.5277, 0.4829, 0.4705, 0.5048]
Val_Loss: 0.538822, Val_Acc: 0.728155

Epoch #094, Train_Loss: [0.5026, 0.4788, 0.4422, 0.4646, 0.3803, 0.4611, 0.5062, 0.5669, 0.5155, 0.4623, 0.5433, 0.5309, 0.4994, 0.4937, 0.5177, 0.4599, 0.5114, 0.5073, 0.3962, 0.4774, 0.5388, 0.4722, 0.4846, 0.5602, 0.4290, 0.5608]
Val_Loss: 0.528825, Val_Acc: 0.737864

Epoch #095, Train_Loss: [0.4676, 0.4551, 0.5181, 0.4880, 0.4136, 0.4422, 0.4301, 0.4570, 0.4709, 0.4866, 0.5085, 0.4769, 0.5113, 0.5395, 0.5585, 0.5000, 0.4967, 0.5218, 0.4589, 0.5170, 0.4753, 0.4844, 0.4843, 0.4848, 0.4664, 0.4953]
Val_Loss: 0.536063, Val_Acc: 0.728155

Epoch #096, Train_Loss: [0.5080, 0.5394, 0.5334, 0.4141, 0.4829, 0.4880, 0.4837, 0.5438, 0.5258, 0.4865, 0.5047, 0.4997, 0.5010, 0.4755, 0.4890, 0.4929, 0.4473, 0.5143, 0.5562, 0.4640, 0.5184, 0.4739, 0.4966, 0.4959, 0.4315, 0.5022]
Val_Loss: 0.521352, Val_Acc: 0.740291

Epoch #097, Train_Loss: [0.5643, 0.5245, 0.5165, 0.4876, 0.4810, 0.5356, 0.4713, 0.4931, 0.5296, 0.4557, 0.4626, 0.5044, 0.4634, 0.5503, 0.5494, 0.4728, 0.4860, 0.3993, 0.4313, 0.4210, 0.4730, 0.5543, 0.5116, 0.5159, 0.4776, 0.5232]
Val_Loss: 0.536554, Val_Acc: 0.733010

Epoch #098, Train_Loss: [0.5854, 0.4659, 0.4343, 0.4212, 0.4360, 0.5064, 0.4921, 0.5058, 0.5024, 0.4676, 0.5018, 0.5330, 0.5001, 0.4824, 0.4713, 0.4676, 0.4951, 0.5943, 0.4791, 0.5404, 0.4125, 0.5409, 0.5441, 0.5064, 0.4604, 0.4588]
Val_Loss: 0.517550, Val_Acc: 0.745146

Epoch #099, Train_Loss: [0.4289, 0.4770, 0.5105, 0.4785, 0.5064, 0.5146, 0.4669, 0.4751, 0.4818, 0.5420, 0.5389, 0.4745, 0.4491, 0.5307, 0.4361, 0.4341, 0.4518, 0.4985, 0.5316, 0.4692, 0.5569, 0.4570, 0.6339, 0.4721, 0.5096, 0.3799]
Val_Loss: 0.519150, Val_Acc: 0.742718

Epoch #100, Train_Loss: [0.4790, 0.4431, 0.4938, 0.4735, 0.6118, 0.5387, 0.4308, 0.4913, 0.4571, 0.4356, 0.4818, 0.5550, 0.4625, 0.4757, 0.4961, 0.4719, 0.4872, 0.4744, 0.4965, 0.4668, 0.4863, 0.6469, 0.4620, 0.4480, 0.4558, 0.5914]
Val_Loss: 0.527208, Val_Acc: 0.737864

Epoch #101, Train_Loss: [0.5006, 0.5072, 0.5027, 0.5291, 0.5290, 0.4187, 0.5119, 0.4660, 0.4474, 0.5366, 0.4770, 0.4624, 0.5093, 0.4640, 0.5120, 0.4802, 0.5160, 0.3603, 0.5152, 0.5752, 0.4577, 0.5226, 0.5266, 0.4360, 0.5962, 0.5390]
Val_Loss: 0.530591, Val_Acc: 0.737864

Epoch #102, Train_Loss: [0.5894, 0.5207, 0.5267, 0.5312, 0.4677, 0.5131, 0.4673, 0.4558, 0.5269, 0.4808, 0.4011, 0.4996, 0.5101, 0.4821, 0.4828, 0.4965, 0.5041, 0.5140, 0.4599, 0.5144, 0.3800, 0.4367, 0.5470, 0.4569, 0.4028, 0.4811]
Val_Loss: 0.524411, Val_Acc: 0.737864

Epoch #103, Train_Loss: [0.4806, 0.5205, 0.5202, 0.5133, 0.3862, 0.4544, 0.5283, 0.4779, 0.5317, 0.4967, 0.4969, 0.4465, 0.4362, 0.5202, 0.5184, 0.5397, 0.4730, 0.4715, 0.4273, 0.5008, 0.4934, 0.5032, 0.4655, 0.4781, 0.5640, 0.5317]
Val_Loss: 0.522956, Val_Acc: 0.750000

Epoch #104, Train_Loss: [0.5411, 0.4760, 0.4764, 0.4054, 0.5251, 0.5207, 0.4565, 0.4757, 0.4499, 0.4161, 0.4834, 0.4874, 0.4623, 0.4053, 0.5295, 0.4756, 0.4805, 0.4747, 0.4411, 0.5383, 0.4937, 0.4764, 0.4295, 0.5218, 0.5692, 0.5299]
Val_Loss: 0.512268, Val_Acc: 0.747573
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #105, Train_Loss: [0.4811, 0.4900, 0.4916, 0.3959, 0.4707, 0.5268, 0.4916, 0.5082, 0.5084, 0.4746, 0.4561, 0.4969, 0.5185, 0.4038, 0.4309, 0.4546, 0.4942, 0.4536, 0.4698, 0.5184, 0.4652, 0.5422, 0.4236, 0.5713, 0.4442, 0.4830]
Val_Loss: 0.506691, Val_Acc: 0.766990
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #106, Train_Loss: [0.4670, 0.4585, 0.5218, 0.5252, 0.5492, 0.4698, 0.4616, 0.4509, 0.4854, 0.4371, 0.4632, 0.5048, 0.5051, 0.4989, 0.4656, 0.4534, 0.4598, 0.4996, 0.4553, 0.4516, 0.4945, 0.5297, 0.5067, 0.4562, 0.4055, 0.5692]
Val_Loss: 0.510761, Val_Acc: 0.750000

Epoch #107, Train_Loss: [0.4205, 0.4965, 0.4781, 0.4834, 0.4557, 0.4674, 0.4340, 0.4952, 0.4550, 0.5352, 0.4683, 0.5590, 0.4705, 0.4705, 0.4055, 0.4778, 0.5501, 0.4918, 0.5056, 0.4569, 0.4735, 0.4087, 0.4808, 0.4880, 0.5010, 0.4916]
Val_Loss: 0.518138, Val_Acc: 0.740291

Epoch #108, Train_Loss: [0.4303, 0.4727, 0.5104, 0.3752, 0.3997, 0.5101, 0.4551, 0.4646, 0.4312, 0.5482, 0.4580, 0.4691, 0.5216, 0.5060, 0.5365, 0.4571, 0.4745, 0.5527, 0.5772, 0.5374, 0.5528, 0.4743, 0.4466, 0.4870, 0.4970, 0.5071]
Val_Loss: 0.515932, Val_Acc: 0.752427

Epoch #109, Train_Loss: [0.6104, 0.3823, 0.4983, 0.4281, 0.4224, 0.4644, 0.4301, 0.5069, 0.4334, 0.4788, 0.5206, 0.5375, 0.4771, 0.4569, 0.4016, 0.4527, 0.5019, 0.4457, 0.4951, 0.4841, 0.5864, 0.4973, 0.5905, 0.5115, 0.4969, 0.5111]
Val_Loss: 0.515776, Val_Acc: 0.750000

Epoch #110, Train_Loss: [0.4594, 0.4657, 0.5220, 0.4954, 0.4936, 0.4161, 0.4501, 0.4655, 0.4472, 0.4977, 0.4213, 0.5201, 0.5065, 0.5055, 0.5642, 0.5297, 0.5360, 0.4835, 0.5646, 0.5319, 0.4899, 0.4447, 0.5136, 0.4254, 0.4678, 0.4292]
Val_Loss: 0.514195, Val_Acc: 0.747573

Epoch #111, Train_Loss: [0.4106, 0.5057, 0.4877, 0.4900, 0.5083, 0.4580, 0.5229, 0.5197, 0.4930, 0.3932, 0.5392, 0.4438, 0.4290, 0.5686, 0.5054, 0.4662, 0.5280, 0.4862, 0.4780, 0.5412, 0.4577, 0.4206, 0.4649, 0.5294, 0.4854, 0.5601]
Val_Loss: 0.516147, Val_Acc: 0.747573

Epoch #112, Train_Loss: [0.5936, 0.4356, 0.4106, 0.4036, 0.4694, 0.4182, 0.4963, 0.5137, 0.4778, 0.5000, 0.6038, 0.5211, 0.4074, 0.4919, 0.4971, 0.4511, 0.4469, 0.4887, 0.4800, 0.4638, 0.3946, 0.5359, 0.4782, 0.4444, 0.4724, 0.4330]
Val_Loss: 0.519131, Val_Acc: 0.735437

Epoch #113, Train_Loss: [0.4534, 0.4262, 0.5295, 0.5015, 0.4641, 0.4256, 0.4428, 0.4361, 0.4597, 0.4260, 0.4012, 0.5151, 0.4999, 0.5070, 0.5058, 0.4584, 0.5933, 0.5524, 0.5178, 0.4624, 0.4943, 0.5107, 0.4547, 0.4899, 0.4787, 0.4867]
Val_Loss: 0.505305, Val_Acc: 0.750000
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #114, Train_Loss: [0.5321, 0.4255, 0.4535, 0.4659, 0.4458, 0.4908, 0.4764, 0.5071, 0.4688, 0.5015, 0.4826, 0.5294, 0.4320, 0.5249, 0.4754, 0.4572, 0.5396, 0.4485, 0.4748, 0.5319, 0.5068, 0.4659, 0.4525, 0.5575, 0.4691, 0.5326]
Val_Loss: 0.497284, Val_Acc: 0.754854
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #115, Train_Loss: [0.4840, 0.4285, 0.4864, 0.4671, 0.4664, 0.4218, 0.4649, 0.4447, 0.4507, 0.5425, 0.4736, 0.4799, 0.4949, 0.4715, 0.5340, 0.4152, 0.4617, 0.5497, 0.4868, 0.4982, 0.4364, 0.4417, 0.5923, 0.4951, 0.5765, 0.4663]
Val_Loss: 0.525297, Val_Acc: 0.740291

Epoch #116, Train_Loss: [0.4499, 0.5543, 0.4538, 0.5226, 0.4430, 0.6030, 0.5771, 0.4410, 0.5453, 0.4854, 0.5314, 0.4947, 0.5279, 0.4286, 0.5526, 0.4465, 0.4689, 0.5991, 0.5271, 0.4846, 0.5432, 0.5477, 0.4547, 0.4930, 0.4866, 0.4886]
Val_Loss: 0.507778, Val_Acc: 0.759709

Epoch #117, Train_Loss: [0.4472, 0.4745, 0.4731, 0.4866, 0.4576, 0.4887, 0.5606, 0.4570, 0.4322, 0.4737, 0.4773, 0.5519, 0.5851, 0.5044, 0.4711, 0.4880, 0.3853, 0.5285, 0.4655, 0.4915, 0.4527, 0.4948, 0.4447, 0.4588, 0.4322, 0.5582]
Val_Loss: 0.514531, Val_Acc: 0.730583

Epoch #118, Train_Loss: [0.4797, 0.5023, 0.4870, 0.5174, 0.5165, 0.4950, 0.4985, 0.4584, 0.4421, 0.4689, 0.4343, 0.4355, 0.5100, 0.4401, 0.5531, 0.4247, 0.4592, 0.4375, 0.4342, 0.4344, 0.5048, 0.5239, 0.4630, 0.4558, 0.4832, 0.5757]
Val_Loss: 0.522916, Val_Acc: 0.737864

Epoch #119, Train_Loss: [0.4438, 0.5385, 0.4897, 0.5265, 0.4578, 0.4470, 0.5084, 0.5014, 0.4574, 0.4658, 0.4556, 0.3979, 0.3806, 0.5070, 0.4623, 0.5092, 0.4810, 0.5512, 0.5035, 0.4619, 0.4108, 0.5706, 0.5007, 0.5631, 0.4758, 0.4173]
Val_Loss: 0.504485, Val_Acc: 0.747573

Epoch #120, Train_Loss: [0.5308, 0.4903, 0.4940, 0.4785, 0.4768, 0.3791, 0.4677, 0.4756, 0.5231, 0.4325, 0.4811, 0.5008, 0.4442, 0.4703, 0.4327, 0.5219, 0.5381, 0.4428, 0.4939, 0.4676, 0.5449, 0.4763, 0.4720, 0.5428, 0.4704, 0.5642]
Val_Loss: 0.504796, Val_Acc: 0.742718

Epoch #121, Train_Loss: [0.4118, 0.5327, 0.4550, 0.4642, 0.5531, 0.4949, 0.4261, 0.5014, 0.4196, 0.4679, 0.4422, 0.5311, 0.3964, 0.4344, 0.5223, 0.4792, 0.5196, 0.4413, 0.5014, 0.4737, 0.4800, 0.4767, 0.4729, 0.5698, 0.4432, 0.4205]
Val_Loss: 0.513540, Val_Acc: 0.735437

Epoch #122, Train_Loss: [0.5115, 0.4848, 0.4416, 0.4750, 0.4208, 0.4540, 0.5209, 0.5578, 0.4569, 0.4658, 0.4902, 0.4743, 0.4994, 0.4927, 0.4758, 0.4369, 0.4484, 0.4171, 0.4581, 0.4213, 0.4835, 0.5825, 0.4882, 0.4432, 0.5617, 0.4808]
Val_Loss: 0.508207, Val_Acc: 0.745146

Epoch #123, Train_Loss: [0.4569, 0.4945, 0.4233, 0.4651, 0.5613, 0.4583, 0.4447, 0.4875, 0.4367, 0.5652, 0.3738, 0.5090, 0.4276, 0.3986, 0.4934, 0.4858, 0.3699, 0.5103, 0.4841, 0.4872, 0.5032, 0.4478, 0.5578, 0.4531, 0.4217, 0.4999]
Val_Loss: 0.500309, Val_Acc: 0.764563

Epoch #124, Train_Loss: [0.5458, 0.4383, 0.5350, 0.4672, 0.4936, 0.4905, 0.5146, 0.4646, 0.4636, 0.4560, 0.4367, 0.4728, 0.4455, 0.4578, 0.4417, 0.4625, 0.4572, 0.5744, 0.3992, 0.5533, 0.3941, 0.4346, 0.4342, 0.4905, 0.4882, 0.4853]
Val_Loss: 0.532536, Val_Acc: 0.711165

Epoch #125, Train_Loss: [0.5669, 0.3892, 0.4366, 0.4670, 0.4070, 0.5315, 0.5017, 0.4859, 0.4332, 0.4661, 0.5476, 0.4331, 0.5191, 0.5393, 0.4477, 0.4264, 0.4406, 0.5087, 0.4862, 0.4871, 0.4521, 0.4229, 0.4509, 0.4776, 0.4391, 0.5086]
Val_Loss: 0.497382, Val_Acc: 0.762136

Epoch #126, Train_Loss: [0.5087, 0.4723, 0.4636, 0.5309, 0.4162, 0.4109, 0.4566, 0.5183, 0.4609, 0.4751, 0.4947, 0.5770, 0.4121, 0.4698, 0.5848, 0.4095, 0.6110, 0.4688, 0.4519, 0.4528, 0.4950, 0.4598, 0.4636, 0.4431, 0.4025, 0.4015]
Val_Loss: 0.505260, Val_Acc: 0.762136

Epoch #127, Train_Loss: [0.4960, 0.4278, 0.4588, 0.4777, 0.5068, 0.5316, 0.5305, 0.4562, 0.4770, 0.5848, 0.4460, 0.4350, 0.4955, 0.4196, 0.4191, 0.5072, 0.4927, 0.4718, 0.4556, 0.4978, 0.3869, 0.5326, 0.5327, 0.4120, 0.5266, 0.4643]
Val_Loss: 0.512315, Val_Acc: 0.747573

Epoch #128, Train_Loss: [0.5120, 0.4818, 0.4944, 0.4890, 0.4943, 0.4887, 0.4401, 0.3808, 0.5100, 0.4211, 0.4483, 0.4924, 0.5316, 0.4677, 0.4959, 0.4447, 0.5089, 0.4559, 0.4677, 0.3915, 0.4733, 0.4348, 0.4735, 0.4497, 0.4659, 0.4030]
Val_Loss: 0.507140, Val_Acc: 0.750000

Epoch #129, Train_Loss: [0.4948, 0.4942, 0.4266, 0.5103, 0.4359, 0.4288, 0.4679, 0.4285, 0.4740, 0.4734, 0.4949, 0.5236, 0.4232, 0.4558, 0.4588, 0.4079, 0.4453, 0.4951, 0.4437, 0.4951, 0.5137, 0.5045, 0.4888, 0.5015, 0.5033, 0.5338]
Val_Loss: 0.502001, Val_Acc: 0.750000

Epoch #130, Train_Loss: [0.4521, 0.4753, 0.4550, 0.5013, 0.4873, 0.4687, 0.5019, 0.5543, 0.4370, 0.4172, 0.4959, 0.5026, 0.4399, 0.4884, 0.4192, 0.5233, 0.4466, 0.4892, 0.4816, 0.4369, 0.3691, 0.4695, 0.5079, 0.4587, 0.4938, 0.4372]
Val_Loss: 0.505985, Val_Acc: 0.762136

Epoch #131, Train_Loss: [0.3992, 0.4984, 0.4444, 0.4600, 0.4272, 0.4413, 0.5273, 0.4140, 0.4459, 0.5609, 0.4624, 0.4980, 0.4253, 0.5817, 0.4243, 0.4878, 0.5303, 0.4759, 0.3695, 0.5211, 0.4496, 0.4896, 0.3915, 0.4925, 0.4898, 0.4079]
Val_Loss: 0.511632, Val_Acc: 0.747573

Epoch #132, Train_Loss: [0.4714, 0.4912, 0.5380, 0.5037, 0.4995, 0.4642, 0.4675, 0.4266, 0.4573, 0.3996, 0.4942, 0.4373, 0.4159, 0.5103, 0.4697, 0.5457, 0.4410, 0.4451, 0.4468, 0.3635, 0.4492, 0.5192, 0.4780, 0.3874, 0.4825, 0.3896]
Val_Loss: 0.514126, Val_Acc: 0.750000

Epoch #133, Train_Loss: [0.4353, 0.4684, 0.5087, 0.4205, 0.4874, 0.3925, 0.4410, 0.4425, 0.5125, 0.4591, 0.5374, 0.4279, 0.5360, 0.4902, 0.4233, 0.4377, 0.4834, 0.5642, 0.4628, 0.4293, 0.4667, 0.4239, 0.4626, 0.5367, 0.4501, 0.4704]
Val_Loss: 0.496139, Val_Acc: 0.752427
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #134, Train_Loss: [0.4357, 0.3539, 0.5154, 0.4636, 0.5442, 0.4703, 0.4743, 0.4678, 0.4547, 0.4090, 0.5227, 0.4969, 0.4361, 0.5586, 0.4017, 0.4203, 0.5048, 0.4923, 0.4412, 0.4204, 0.5024, 0.4599, 0.4429, 0.4361, 0.4342, 0.4971]
Val_Loss: 0.499885, Val_Acc: 0.757282

Epoch #135, Train_Loss: [0.4494, 0.4737, 0.3946, 0.4284, 0.4618, 0.5449, 0.4667, 0.4291, 0.4263, 0.3960, 0.5780, 0.4189, 0.4862, 0.4484, 0.4438, 0.4212, 0.4395, 0.5236, 0.4020, 0.5291, 0.4409, 0.5210, 0.4242, 0.4817, 0.4614, 0.4401]
Val_Loss: 0.504910, Val_Acc: 0.759709

Epoch #136, Train_Loss: [0.4283, 0.4772, 0.4114, 0.5618, 0.3615, 0.5100, 0.4453, 0.4110, 0.4054, 0.3881, 0.4331, 0.4500, 0.4279, 0.4152, 0.6498, 0.5404, 0.4321, 0.4022, 0.4529, 0.4364, 0.5165, 0.5459, 0.5192, 0.4153, 0.5423, 0.5296]
Val_Loss: 0.500281, Val_Acc: 0.740291

Epoch #137, Train_Loss: [0.5651, 0.4768, 0.4437, 0.5163, 0.5502, 0.4356, 0.4966, 0.4621, 0.3853, 0.4564, 0.3979, 0.4488, 0.4458, 0.4603, 0.3631, 0.5193, 0.4616, 0.5358, 0.5270, 0.5008, 0.5445, 0.3968, 0.4185, 0.4173, 0.5317, 0.3396]
Val_Loss: 0.502279, Val_Acc: 0.762136

Epoch #138, Train_Loss: [0.4897, 0.4611, 0.4508, 0.4456, 0.4774, 0.5001, 0.4969, 0.4951, 0.4623, 0.4540, 0.4686, 0.4317, 0.5125, 0.5147, 0.4654, 0.4911, 0.5232, 0.4674, 0.5416, 0.5048, 0.4256, 0.4888, 0.4506, 0.4887, 0.4713, 0.4683]
Val_Loss: 0.499330, Val_Acc: 0.747573

Epoch #139, Train_Loss: [0.3698, 0.3895, 0.4265, 0.4913, 0.4445, 0.5266, 0.4483, 0.4384, 0.4360, 0.4030, 0.4733, 0.4657, 0.5109, 0.5832, 0.3933, 0.4570, 0.5837, 0.4384, 0.5576, 0.5246, 0.4833, 0.4413, 0.5150, 0.5625, 0.4290, 0.5504]
Val_Loss: 0.506991, Val_Acc: 0.757282

Epoch #140, Train_Loss: [0.5360, 0.4192, 0.4756, 0.4083, 0.4963, 0.4476, 0.4548, 0.4545, 0.4733, 0.4668, 0.4865, 0.4395, 0.4396, 0.4479, 0.5235, 0.4854, 0.4532, 0.4645, 0.4579, 0.4650, 0.4491, 0.5041, 0.4672, 0.4496, 0.5775, 0.4231]
Val_Loss: 0.495559, Val_Acc: 0.762136
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #141, Train_Loss: [0.4757, 0.4672, 0.4043, 0.4360, 0.4257, 0.4765, 0.4741, 0.3735, 0.4721, 0.4662, 0.3595, 0.4860, 0.5138, 0.3928, 0.5177, 0.5003, 0.3830, 0.4627, 0.5029, 0.4399, 0.4760, 0.5122, 0.5053, 0.4644, 0.5125, 0.5830]
Val_Loss: 0.512027, Val_Acc: 0.754854

Epoch #142, Train_Loss: [0.3883, 0.4508, 0.4541, 0.4589, 0.5470, 0.4607, 0.4587, 0.4191, 0.4788, 0.4506, 0.5081, 0.3719, 0.5564, 0.4349, 0.3555, 0.5019, 0.4069, 0.4039, 0.5681, 0.5745, 0.4694, 0.5080, 0.4372, 0.3961, 0.5130, 0.3777]
Val_Loss: 0.486567, Val_Acc: 0.776699
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #143, Train_Loss: [0.4110, 0.4192, 0.4467, 0.4068, 0.4577, 0.4288, 0.4610, 0.4306, 0.4833, 0.4803, 0.5089, 0.3417, 0.4878, 0.4781, 0.4289, 0.4363, 0.4611, 0.4866, 0.4496, 0.5009, 0.5162, 0.5196, 0.4881, 0.4074, 0.4063, 0.4947]
Val_Loss: 0.492488, Val_Acc: 0.757282

Epoch #144, Train_Loss: [0.4691, 0.4212, 0.4091, 0.4521, 0.4254, 0.4799, 0.4123, 0.4469, 0.5425, 0.4251, 0.4582, 0.4318, 0.5078, 0.4971, 0.4670, 0.4629, 0.4198, 0.4652, 0.4887, 0.4548, 0.4036, 0.4747, 0.5467, 0.4275, 0.4929, 0.4766]
Val_Loss: 0.501740, Val_Acc: 0.752427

Epoch #145, Train_Loss: [0.4849, 0.3891, 0.4725, 0.4330, 0.4625, 0.4962, 0.4372, 0.4316, 0.4361, 0.5723, 0.4566, 0.4505, 0.4718, 0.5200, 0.4690, 0.3999, 0.5097, 0.4105, 0.3921, 0.4179, 0.5022, 0.3396, 0.4447, 0.4809, 0.4829, 0.4282]
Val_Loss: 0.500277, Val_Acc: 0.757282

Epoch #146, Train_Loss: [0.4026, 0.4384, 0.4820, 0.4149, 0.4078, 0.4066, 0.4542, 0.3626, 0.5101, 0.4269, 0.4748, 0.4090, 0.5439, 0.4177, 0.4720, 0.4553, 0.6009, 0.3941, 0.5109, 0.4387, 0.5157, 0.5569, 0.4769, 0.4460, 0.5223, 0.5059]
Val_Loss: 0.498768, Val_Acc: 0.757282

Epoch #147, Train_Loss: [0.4327, 0.4503, 0.4308, 0.4778, 0.5135, 0.4461, 0.4263, 0.4628, 0.4485, 0.4811, 0.4306, 0.4097, 0.4760, 0.4040, 0.4930, 0.4493, 0.4815, 0.4356, 0.4938, 0.4712, 0.5181, 0.5012, 0.4241, 0.4493, 0.4868, 0.4422]
Val_Loss: 0.493813, Val_Acc: 0.754854

Epoch #148, Train_Loss: [0.4381, 0.4282, 0.4088, 0.3934, 0.4358, 0.4629, 0.5286, 0.3925, 0.4294, 0.4435, 0.4465, 0.4761, 0.6045, 0.4532, 0.4315, 0.4598, 0.4716, 0.4245, 0.4825, 0.5121, 0.3865, 0.5062, 0.4516, 0.5086, 0.4408, 0.4182]
Val_Loss: 0.487985, Val_Acc: 0.769417

Epoch #149, Train_Loss: [0.4655, 0.4529, 0.5132, 0.4297, 0.4267, 0.4792, 0.4901, 0.4101, 0.5304, 0.3867, 0.5100, 0.4122, 0.4230, 0.5120, 0.4192, 0.4398, 0.4071, 0.4674, 0.5112, 0.5851, 0.4710, 0.3870, 0.4269, 0.4793, 0.4506, 0.5034]
Val_Loss: 0.493437, Val_Acc: 0.762136

Epoch #150, Train_Loss: [0.4275, 0.4653, 0.5213, 0.3788, 0.5203, 0.4554, 0.5068, 0.3726, 0.4774, 0.5028, 0.3565, 0.4673, 0.4358, 0.3632, 0.3740, 0.4847, 0.5152, 0.4576, 0.4605, 0.4529, 0.4400, 0.4144, 0.4567, 0.4875, 0.3979, 0.3729]
Val_Loss: 0.499603, Val_Acc: 0.771845

Epoch #151, Train_Loss: [0.5012, 0.5395, 0.4535, 0.4084, 0.4685, 0.4775, 0.4818, 0.4453, 0.3567, 0.4430, 0.5198, 0.4809, 0.4916, 0.4598, 0.4378, 0.4298, 0.4308, 0.3980, 0.4544, 0.4659, 0.3873, 0.4093, 0.4912, 0.5014, 0.3727, 0.5075]
Val_Loss: 0.505457, Val_Acc: 0.762136

Epoch #152, Train_Loss: [0.4617, 0.5018, 0.5005, 0.4845, 0.3992, 0.4392, 0.4399, 0.4924, 0.4049, 0.4769, 0.4453, 0.4107, 0.4386, 0.5411, 0.4185, 0.4355, 0.4801, 0.4411, 0.4656, 0.4684, 0.3074, 0.4523, 0.4901, 0.3206, 0.5211, 0.4134]
Val_Loss: 0.508972, Val_Acc: 0.764563

Epoch #153, Train_Loss: [0.4540, 0.4109, 0.4848, 0.3768, 0.3733, 0.5420, 0.4501, 0.4562, 0.4975, 0.3902, 0.4522, 0.3926, 0.5174, 0.4643, 0.4091, 0.4658, 0.4603, 0.3806, 0.4780, 0.4234, 0.5001, 0.4913, 0.4007, 0.3855, 0.4333, 0.4475]
Val_Loss: 0.498042, Val_Acc: 0.764563

Epoch #154, Train_Loss: [0.5084, 0.5173, 0.5063, 0.3938, 0.4054, 0.5752, 0.4205, 0.5366, 0.4624, 0.5648, 0.4689, 0.4910, 0.4209, 0.5170, 0.4733, 0.5006, 0.4605, 0.4543, 0.4837, 0.4566, 0.4763, 0.4245, 0.4539, 0.4540, 0.4969, 0.4617]
Val_Loss: 0.491975, Val_Acc: 0.757282

Epoch #155, Train_Loss: [0.4054, 0.4567, 0.4244, 0.4982, 0.5257, 0.4004, 0.4892, 0.4442, 0.4663, 0.4091, 0.4220, 0.4594, 0.4130, 0.5623, 0.3483, 0.4824, 0.4588, 0.4395, 0.4967, 0.4813, 0.4717, 0.4805, 0.4089, 0.4214, 0.4217, 0.5109]
Val_Loss: 0.496763, Val_Acc: 0.740291

Epoch #156, Train_Loss: [0.4615, 0.4000, 0.4690, 0.3788, 0.4352, 0.4481, 0.4731, 0.4150, 0.3755, 0.5264, 0.4326, 0.3853, 0.5286, 0.4103, 0.4504, 0.4937, 0.5295, 0.4431, 0.5225, 0.4743, 0.5001, 0.4722, 0.4059, 0.4667, 0.4973, 0.5094]
Val_Loss: 0.514063, Val_Acc: 0.745146

Epoch #157, Train_Loss: [0.4764, 0.4271, 0.4579, 0.4944, 0.4612, 0.4369, 0.4231, 0.4631, 0.4113, 0.4619, 0.4293, 0.4983, 0.4372, 0.4873, 0.3731, 0.4768, 0.4974, 0.3793, 0.4192, 0.3842, 0.4613, 0.5326, 0.3957, 0.4202, 0.4504, 0.3775]
Val_Loss: 0.513409, Val_Acc: 0.745146

Epoch #158, Train_Loss: [0.4222, 0.3992, 0.4945, 0.4497, 0.5046, 0.5138, 0.4842, 0.4730, 0.4370, 0.4371, 0.4596, 0.3687, 0.3933, 0.4129, 0.4044, 0.4474, 0.3523, 0.5299, 0.4768, 0.4251, 0.3526, 0.3981, 0.4353, 0.4854, 0.4550, 0.4781]
Val_Loss: 0.505810, Val_Acc: 0.757282

Epoch #159, Train_Loss: [0.4180, 0.3581, 0.5210, 0.4692, 0.4350, 0.4513, 0.4286, 0.4364, 0.5652, 0.3994, 0.4024, 0.4503, 0.5037, 0.3736, 0.3875, 0.4926, 0.4639, 0.4187, 0.4446, 0.4369, 0.4826, 0.4739, 0.3515, 0.4735, 0.4565, 0.4384]
Val_Loss: 0.496509, Val_Acc: 0.774272

Epoch #160, Train_Loss: [0.4007, 0.4067, 0.4671, 0.4024, 0.5062, 0.4195, 0.4849, 0.5074, 0.3786, 0.4439, 0.4810, 0.5138, 0.5010, 0.3853, 0.4254, 0.3861, 0.3868, 0.4451, 0.5426, 0.5061, 0.3941, 0.4602, 0.4278, 0.4228, 0.5112, 0.3405]
Val_Loss: 0.499392, Val_Acc: 0.771845

Epoch #161, Train_Loss: [0.4384, 0.4296, 0.4809, 0.4383, 0.4688, 0.4451, 0.4154, 0.4188, 0.4424, 0.4369, 0.4134, 0.4465, 0.4089, 0.6549, 0.4185, 0.5338, 0.4349, 0.4802, 0.4581, 0.4594, 0.4695, 0.4520, 0.4514, 0.4960, 0.4159, 0.4151]
Val_Loss: 0.507441, Val_Acc: 0.750000

Epoch #162, Train_Loss: [0.3673, 0.4563, 0.4547, 0.5242, 0.4469, 0.5190, 0.3859, 0.4686, 0.4311, 0.4587, 0.3744, 0.4601, 0.5087, 0.4790, 0.5161, 0.4295, 0.3601, 0.4573, 0.4194, 0.4322, 0.5639, 0.4405, 0.4552, 0.4763, 0.4957, 0.5088]
Val_Loss: 0.541638, Val_Acc: 0.733010

Epoch #163, Train_Loss: [0.4705, 0.5127, 0.4505, 0.4338, 0.4430, 0.4472, 0.5571, 0.4519, 0.4143, 0.4602, 0.3948, 0.4191, 0.5230, 0.3922, 0.4268, 0.5616, 0.5044, 0.3288, 0.4089, 0.4152, 0.4767, 0.4660, 0.4456, 0.4651, 0.4218, 0.3544]
Val_Loss: 0.513536, Val_Acc: 0.754854

Epoch #164, Train_Loss: [0.4278, 0.4910, 0.4208, 0.3816, 0.4238, 0.3810, 0.4398, 0.4042, 0.4819, 0.4759, 0.4336, 0.4526, 0.4203, 0.4391, 0.4705, 0.4939, 0.4205, 0.4358, 0.4198, 0.4961, 0.4385, 0.4893, 0.4209, 0.4632, 0.4359, 0.3699]
Val_Loss: 0.491414, Val_Acc: 0.766990

Epoch #165, Train_Loss: [0.4380, 0.4435, 0.4566, 0.4630, 0.3756, 0.4517, 0.3943, 0.5006, 0.4639, 0.4048, 0.4821, 0.4425, 0.5067, 0.3644, 0.4715, 0.4367, 0.4897, 0.4641, 0.4077, 0.4732, 0.5040, 0.3989, 0.4903, 0.4686, 0.4195, 0.4338]
Val_Loss: 0.480622, Val_Acc: 0.776699
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********

Epoch #166, Train_Loss: [0.4998, 0.4529, 0.4200, 0.4893, 0.4676, 0.4947, 0.4026, 0.5015, 0.4343, 0.4423, 0.4872, 0.4700, 0.4345, 0.4507, 0.4462, 0.4121, 0.4288, 0.4466, 0.4041, 0.5643, 0.3652, 0.4154, 0.4197, 0.3560, 0.5365, 0.4323]
Val_Loss: 0.501418, Val_Acc: 0.759709

Epoch #167, Train_Loss: [0.3755, 0.4253, 0.4366, 0.4244, 0.3961, 0.4404, 0.4265, 0.3978, 0.4328, 0.4144, 0.4734, 0.4356, 0.4021, 0.4242, 0.4257, 0.4548, 0.4805, 0.4667, 0.3541, 0.4000, 0.4715, 0.4630, 0.4226, 0.4438, 0.5502, 0.4447]
Val_Loss: 0.496568, Val_Acc: 0.766990

Epoch #168, Train_Loss: [0.4556, 0.4057, 0.5456, 0.4119, 0.4531, 0.3518, 0.4419, 0.4255, 0.3820, 0.4937, 0.4183, 0.4304, 0.4807, 0.4233, 0.4739, 0.4277, 0.4459, 0.4546, 0.4757, 0.4921, 0.3847, 0.4504, 0.5038, 0.4580, 0.4216, 0.4338]
Val_Loss: 0.486383, Val_Acc: 0.766990

Epoch #169, Train_Loss: [0.4406, 0.4235, 0.5389, 0.3960, 0.3871, 0.4450, 0.4919, 0.4419, 0.4410, 0.4077, 0.4241, 0.3682, 0.4675, 0.4300, 0.3915, 0.4468, 0.4613, 0.4373, 0.4971, 0.3984, 0.4235, 0.5041, 0.3877, 0.4648, 0.4525, 0.3854]
Val_Loss: 0.484416, Val_Acc: 0.752427

Epoch #170, Train_Loss: [0.4778, 0.3649, 0.4813, 0.4351, 0.3093, 0.4174, 0.4132, 0.4209, 0.3730, 0.3988, 0.4544, 0.4526, 0.4254, 0.5019, 0.4053, 0.4853, 0.4858, 0.4437, 0.5059, 0.4287, 0.4511, 0.4598, 0.4944, 0.4208, 0.3709, 0.5389]
Val_Loss: 0.507300, Val_Acc: 0.750000

Epoch #171, Train_Loss: [0.4153, 0.4904, 0.4648, 0.5154, 0.5549, 0.3695, 0.3521, 0.4463, 0.4963, 0.3379, 0.5097, 0.4034, 0.4723, 0.5295, 0.3700, 0.3942, 0.5214, 0.4229, 0.4420, 0.3961, 0.4677, 0.3637, 0.4404, 0.4478, 0.3912, 0.4255]
Val_Loss: 0.490232, Val_Acc: 0.766990

Epoch #172, Train_Loss: [0.4768, 0.4481, 0.4446, 0.3968, 0.4437, 0.4570, 0.4306, 0.3983, 0.4629, 0.4068, 0.3768, 0.4800, 0.4431, 0.4816, 0.5085, 0.3375, 0.4292, 0.4423, 0.4074, 0.3894, 0.4775, 0.4160, 0.4239, 0.3998, 0.5073, 0.3779]
Val_Loss: 0.540344, Val_Acc: 0.725728

Epoch #173, Train_Loss: [0.5443, 0.4488, 0.4522, 0.4369, 0.4129, 0.4259, 0.6138, 0.4368, 0.4753, 0.4648, 0.4812, 0.4999, 0.5462, 0.4907, 0.3987, 0.4450, 0.4583, 0.3845, 0.4703, 0.4481, 0.3939, 0.3974, 0.4507, 0.5214, 0.4622, 0.4201]
Val_Loss: 0.489231, Val_Acc: 0.769417

Epoch #174, Train_Loss: [0.4135, 0.4718, 0.4212, 0.4403, 0.4040, 0.4060, 0.4481, 0.4254, 0.4713, 0.4281, 0.3358, 0.4700, 0.4307, 0.4417, 0.4545, 0.4090, 0.4525, 0.3643, 0.4151, 0.4159, 0.5036, 0.5360, 0.5006, 0.4306, 0.4928, 0.3672]
Val_Loss: 0.511240, Val_Acc: 0.747573

Epoch #175, Train_Loss: [0.3861, 0.4968, 0.4789, 0.5514, 0.4202, 0.4748, 0.4160, 0.4043, 0.4522, 0.4682, 0.4049, 0.4311, 0.3847, 0.4985, 0.4507, 0.3956, 0.3311, 0.4271, 0.4825, 0.4106, 0.4543, 0.4708, 0.4047, 0.4345, 0.4135, 0.3986]
Val_Loss: 0.510628, Val_Acc: 0.762136

Epoch #176, Train_Loss: [0.4343, 0.4068, 0.4259, 0.4080, 0.4576, 0.4412, 0.4481, 0.4190, 0.3743, 0.4992, 0.4815, 0.4287, 0.4659, 0.4644, 0.4172, 0.4979, 0.4594, 0.4708, 0.5065, 0.4506, 0.4788, 0.3821, 0.4972, 0.3645, 0.3596, 0.4153]
Val_Loss: 0.522620, Val_Acc: 0.740291

Epoch #177, Train_Loss: [0.4555, 0.4521, 0.4249, 0.4062, 0.4589, 0.4041, 0.4858, 0.4020, 0.3245, 0.5457, 0.4810, 0.4637, 0.3948, 0.3401, 0.4838, 0.4125, 0.3672, 0.5593, 0.3993, 0.5120, 0.3846, 0.4221, 0.3727, 0.3892, 0.4674, 0.4052]
Val_Loss: 0.495497, Val_Acc: 0.762136

Epoch #178, Train_Loss: [0.4166, 0.4730, 0.3995, 0.4545, 0.5158, 0.3747, 0.4863, 0.4545, 0.3994, 0.4887, 0.3660, 0.4238, 0.4344, 0.4163, 0.3681, 0.4523, 0.4349, 0.3947, 0.4416, 0.4232, 0.4524, 0.4506, 0.4366, 0.3642, 0.4893, 0.4718]
Val_Loss: 0.482004, Val_Acc: 0.776699

Epoch #179, Train_Loss: [0.4139, 0.4143, 0.4346, 0.4060, 0.4320, 0.4365, 0.3876, 0.3511, 0.4436, 0.4572, 0.5115, 0.4410, 0.4249, 0.4376, 0.4074, 0.3862, 0.4620, 0.4446, 0.4262, 0.5053, 0.4190, 0.5164, 0.4542, 0.4348, 0.4376, 0.5120]
Val_Loss: 0.518025, Val_Acc: 0.747573

Epoch #180, Train_Loss: [0.4677, 0.3923, 0.4309, 0.3616, 0.5059, 0.4217, 0.3640, 0.4414, 0.4534, 0.4228, 0.4329, 0.4506, 0.4296, 0.4863, 0.3483, 0.4114, 0.4088, 0.4420, 0.4588, 0.4487, 0.4192, 0.5217, 0.4639, 0.5047, 0.4583, 0.4834]
Val_Loss: 0.517087, Val_Acc: 0.730583

Epoch #181, Train_Loss: [0.4337, 0.4315, 0.4169, 0.5269, 0.4270, 0.4232, 0.4348, 0.4522, 0.4380, 0.5175, 0.4796, 0.4236, 0.4495, 0.3567, 0.5007, 0.4123, 0.4555, 0.4740, 0.4692, 0.3833, 0.4763, 0.4209, 0.4178, 0.3789, 0.4299, 0.4530]
Val_Loss: 0.497427, Val_Acc: 0.762136

Epoch #182, Train_Loss: [0.4940, 0.4156, 0.3996, 0.4400, 0.4335, 0.4146, 0.3395, 0.4819, 0.5236, 0.4088, 0.4009, 0.3936, 0.3810, 0.4091, 0.3909, 0.5102, 0.5058, 0.4823, 0.3854, 0.4265, 0.4392, 0.4281, 0.4546, 0.4222, 0.4210, 0.4158]
Val_Loss: 0.501349, Val_Acc: 0.769417

Epoch #183, Train_Loss: [0.5104, 0.4579, 0.4112, 0.4670, 0.4221, 0.4307, 0.4201, 0.5057, 0.4489, 0.3758, 0.3639, 0.4231, 0.4639, 0.4108, 0.4933, 0.3629, 0.4356, 0.4605, 0.4667, 0.4277, 0.3683, 0.3766, 0.4261, 0.4138, 0.4414, 0.5159]
Val_Loss: 0.501036, Val_Acc: 0.769417

Epoch #184, Train_Loss: [0.4469, 0.4167, 0.3857, 0.3789, 0.4359, 0.4950, 0.4087, 0.4428, 0.5008, 0.3940, 0.4059, 0.4611, 0.5103, 0.4100, 0.3826, 0.3917, 0.4143, 0.4883, 0.3404, 0.4833, 0.4184, 0.4216, 0.4213, 0.4653, 0.3765, 0.4482]
Val_Loss: 0.489226, Val_Acc: 0.783981

Epoch #185, Train_Loss: [0.4492, 0.3792, 0.4257, 0.4621, 0.4210, 0.3871, 0.4051, 0.4668, 0.4203, 0.3663, 0.5075, 0.3849, 0.4392, 0.3809, 0.4057, 0.5322, 0.3995, 0.4967, 0.4108, 0.4182, 0.5117, 0.3778, 0.4555, 0.4171, 0.4975, 0.4349]
Val_Loss: 0.507307, Val_Acc: 0.769417

Epoch #186, Train_Loss: [0.3952, 0.4445, 0.4535, 0.4813, 0.4137, 0.4520, 0.4813, 0.4007, 0.4700, 0.3307, 0.4294, 0.3783, 0.3652, 0.4361, 0.5741, 0.4714, 0.4177, 0.4013, 0.3496, 0.3896, 0.4692, 0.3903, 0.4837, 0.4271, 0.3652, 0.3929]
Val_Loss: 0.508928, Val_Acc: 0.759709

Epoch #187, Train_Loss: [0.3917, 0.4584, 0.3048, 0.4486, 0.6112, 0.4303, 0.3944, 0.5059, 0.3594, 0.4028, 0.4758, 0.3848, 0.4065, 0.3940, 0.4258, 0.4195, 0.3591, 0.4416, 0.4503, 0.4489, 0.4146, 0.4854, 0.4770, 0.4599, 0.4113, 0.4800]
Val_Loss: 0.512996, Val_Acc: 0.750000

Epoch #188, Train_Loss: [0.3834, 0.4507, 0.4615, 0.4036, 0.4446, 0.4160, 0.3862, 0.4729, 0.4032, 0.4032, 0.3650, 0.3967, 0.3743, 0.4195, 0.4199, 0.4183, 0.4015, 0.3765, 0.4436, 0.4573, 0.4480, 0.4940, 0.5156, 0.4213, 0.4367, 0.5650]
Val_Loss: 0.490999, Val_Acc: 0.776699

Epoch #189, Train_Loss: [0.3719, 0.3980, 0.4482, 0.3500, 0.4422, 0.4498, 0.4564, 0.4374, 0.4170, 0.4650, 0.4725, 0.5270, 0.3605, 0.3520, 0.4895, 0.3940, 0.3103, 0.4321, 0.4231, 0.4517, 0.4124, 0.4732, 0.4154, 0.5581, 0.3587, 0.3817]
Val_Loss: 0.495137, Val_Acc: 0.779126

Epoch #190, Train_Loss: [0.3692, 0.4689, 0.3527, 0.5040, 0.4671, 0.4268, 0.4341, 0.4414, 0.4452, 0.5063, 0.4387, 0.4234, 0.4470, 0.4418, 0.5016, 0.4229, 0.3972, 0.3434, 0.4673, 0.3899, 0.5028, 0.3546, 0.4398, 0.4411, 0.4147, 0.4586]
Val_Loss: 0.490467, Val_Acc: 0.786408

Epoch #191, Train_Loss: [0.4177, 0.4711, 0.4302, 0.4168, 0.3512, 0.5118, 0.4256, 0.3993, 0.4322, 0.4452, 0.5070, 0.4493, 0.4600, 0.3647, 0.4221, 0.4099, 0.4348, 0.4056, 0.4555, 0.4338, 0.3634, 0.4990, 0.4618, 0.4087, 0.3870, 0.3343]
Val_Loss: 0.498844, Val_Acc: 0.774272

Epoch #192, Train_Loss: [0.4002, 0.4059, 0.4933, 0.3561, 0.4402, 0.3889, 0.3905, 0.3954, 0.3881, 0.4148, 0.5542, 0.5559, 0.3537, 0.3596, 0.4424, 0.4754, 0.5018, 0.3674, 0.4016, 0.5381, 0.4026, 0.4615, 0.4569, 0.4169, 0.4473, 0.3950]
Val_Loss: 0.503808, Val_Acc: 0.742718

Epoch #193, Train_Loss: [0.4978, 0.3950, 0.4505, 0.3853, 0.4389, 0.5463, 0.5821, 0.5115, 0.3739, 0.4189, 0.3908, 0.3729, 0.4047, 0.3415, 0.3851, 0.4880, 0.4602, 0.4577, 0.4644, 0.4378, 0.5088, 0.3859, 0.4352, 0.3899, 0.4608, 0.4392]
Val_Loss: 0.502150, Val_Acc: 0.766990

Epoch #194, Train_Loss: [0.4813, 0.3836, 0.3863, 0.5022, 0.4203, 0.4420, 0.4459, 0.4080, 0.4503, 0.4441, 0.4134, 0.4189, 0.4257, 0.4276, 0.3367, 0.4662, 0.4082, 0.4425, 0.3634, 0.4040, 0.4066, 0.4225, 0.4650, 0.4312, 0.4501, 0.4450]
Val_Loss: 0.492893, Val_Acc: 0.779126

Epoch #195, Train_Loss: [0.3622, 0.4705, 0.5446, 0.3531, 0.4950, 0.4417, 0.4464, 0.4143, 0.4258, 0.4261, 0.3229, 0.3451, 0.4220, 0.3933, 0.4259, 0.4603, 0.3401, 0.4123, 0.4110, 0.4403, 0.4301, 0.3682, 0.4084, 0.5484, 0.3814, 0.5112]
Val_Loss: 0.487446, Val_Acc: 0.779126

Epoch #196, Train_Loss: [0.3759, 0.4475, 0.3501, 0.4259, 0.4285, 0.4215, 0.3762, 0.4439, 0.4050, 0.3715, 0.5110, 0.4305, 0.4588, 0.4670, 0.4496, 0.4576, 0.4089, 0.3927, 0.4584, 0.4085, 0.4244, 0.3695, 0.4322, 0.4776, 0.3552, 0.4211]
Val_Loss: 0.525100, Val_Acc: 0.750000

Epoch #197, Train_Loss: [0.4539, 0.4070, 0.3892, 0.3451, 0.4415, 0.4448, 0.5144, 0.3963, 0.3418, 0.4791, 0.4645, 0.4102, 0.4346, 0.3501, 0.4157, 0.4178, 0.3906, 0.4530, 0.4410, 0.4529, 0.4257, 0.4261, 0.4266, 0.4712, 0.4375, 0.5640]
Val_Loss: 0.498445, Val_Acc: 0.762136

Epoch #198, Train_Loss: [0.4718, 0.4860, 0.4373, 0.4617, 0.3933, 0.4376, 0.4417, 0.4567, 0.4645, 0.3838, 0.4521, 0.3998, 0.4423, 0.4176, 0.4305, 0.3388, 0.4024, 0.4924, 0.4510, 0.4261, 0.4183, 0.4146, 0.5707, 0.3802, 0.3552, 0.5289]
Val_Loss: 0.504610, Val_Acc: 0.769417

Epoch #199, Train_Loss: [0.3734, 0.4484, 0.4065, 0.4088, 0.4911, 0.4377, 0.4040, 0.4968, 0.3863, 0.4220, 0.4653, 0.5130, 0.3448, 0.4710, 0.4745, 0.3815, 0.4173, 0.3911, 0.4262, 0.4262, 0.5202, 0.3433, 0.4540, 0.3535, 0.4880, 0.3440]
Val_Loss: 0.487251, Val_Acc: 0.771845

Epoch #200, Train_Loss: [0.4879, 0.4145, 0.3470, 0.4916, 0.3833, 0.3947, 0.4774, 0.3699, 0.4579, 0.3773, 0.4360, 0.3792, 0.3798, 0.3986, 0.3645, 0.4538, 0.5192, 0.4248, 0.3539, 0.3690, 0.3969, 0.3451, 0.5243, 0.5112, 0.4999, 0.4254]
Val_Loss: 0.513847, Val_Acc: 0.757282

Epoch #201, Train_Loss: [0.4507, 0.5475, 0.4143, 0.4110, 0.3878, 0.3245, 0.6063, 0.4599, 0.3970, 0.3871, 0.5256, 0.5434, 0.4650, 0.4584, 0.4785, 0.5161, 0.4079, 0.4577, 0.4431, 0.4191, 0.3817, 0.4497, 0.3434, 0.4236, 0.4707, 0.4062]
Val_Loss: 0.496931, Val_Acc: 0.766990

Epoch #202, Train_Loss: [0.4356, 0.4150, 0.4220, 0.3815, 0.4215, 0.4405, 0.4218, 0.4127, 0.4380, 0.3530, 0.3497, 0.4633, 0.5189, 0.4434, 0.3816, 0.4420, 0.3865, 0.4117, 0.4111, 0.4122, 0.4209, 0.3272, 0.4091, 0.3426, 0.4983, 0.4307]
Val_Loss: 0.522687, Val_Acc: 0.750000

Epoch #203, Train_Loss: [0.3417, 0.3546, 0.4529, 0.5292, 0.3930, 0.3866, 0.4059, 0.4663, 0.4252, 0.3739, 0.4807, 0.3557, 0.4289, 0.3810, 0.4408, 0.4011, 0.4243, 0.4155, 0.3784, 0.4492, 0.3629, 0.4570, 0.3992, 0.3823, 0.3936, 0.5507]
Val_Loss: 0.496564, Val_Acc: 0.781553

Epoch #204, Train_Loss: [0.3682, 0.4165, 0.4072, 0.4088, 0.4336, 0.3841, 0.3574, 0.5356, 0.4243, 0.4640, 0.4288, 0.5425, 0.3644, 0.3120, 0.4211, 0.3943, 0.4544, 0.4135, 0.4114, 0.4035, 0.4739, 0.4808, 0.4158, 0.4511, 0.5543, 0.4146]
Val_Loss: 0.507244, Val_Acc: 0.752427

Epoch #205, Train_Loss: [0.4254, 0.4201, 0.3530, 0.3995, 0.3891, 0.4535, 0.4476, 0.4531, 0.3132, 0.4117, 0.5091, 0.3705, 0.4726, 0.4393, 0.3587, 0.4824, 0.4294, 0.3988, 0.4051, 0.4213, 0.4056, 0.5311, 0.3462, 0.4787, 0.4604, 0.3561]
Val_Loss: 0.503256, Val_Acc: 0.769417

Epoch #206, Train_Loss: [0.4048, 0.5232, 0.4809, 0.3637, 0.3252, 0.4135, 0.4552, 0.4605, 0.4322, 0.3529, 0.4101, 0.4709, 0.4417, 0.3887, 0.4291, 0.3811, 0.4805, 0.4173, 0.5056, 0.3396, 0.3263, 0.4648, 0.4456, 0.4436, 0.3807, 0.3841]
Val_Loss: 0.511310, Val_Acc: 0.762136

********** TEST START **********
Reload Best Model
The current best model is saved in: ******** outputs/NCI109_Hie/model.pth *********
TEST :: Test_Acc: 0.731884
