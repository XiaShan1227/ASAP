+-----------------+-------------------+
|    Parameter    |       Value       |
+=================+===================+
| Batch size      | 128               |
+-----------------+-------------------+
| Dataset         | MUTAG             |
+-----------------+-------------------+
| Dropout ratio   | 0.5               |
+-----------------+-------------------+
| Epochs          | 10000             |
+-----------------+-------------------+
| Exp name        | MUTAG_Glo         |
+-----------------+-------------------+
| Gpu index       | 0                 |
+-----------------+-------------------+
| Hid             | 128               |
+-----------------+-------------------+
| Lr              | 0.0005            |
+-----------------+-------------------+
| Model           | ASAPooling_Global |
+-----------------+-------------------+
| Patience        | 40                |
+-----------------+-------------------+
| Pooling ratio   | 0.5               |
+-----------------+-------------------+
| Seed            | 16                |
+-----------------+-------------------+
| Test batch size | 1                 |
+-----------------+-------------------+
| Weight decay    | 0.0001            |
+-----------------+-------------------+
Using GPU: 0
ASAPooling_Global(
  (conv1): GCNConv(7, 128)
  (conv2): GCNConv(128, 128)
  (conv3): GCNConv(128, 128)
  (pool): ASAPooling(384, ratio=0.5)
  (lin1): Linear(in_features=768, out_features=128, bias=True)
  (lin2): Linear(in_features=128, out_features=64, bias=True)
  (classifier): Linear(in_features=64, out_features=2, bias=True)
)
Model Parameter: 438470
Using Adam

Epoch #000, Train_Loss: [0.7190, 0.7233]
Val_Loss: 0.694251, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #001, Train_Loss: [0.7154, 0.7079]
Val_Loss: 0.693294, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #002, Train_Loss: [0.7089, 0.7108]
Val_Loss: 0.692574, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #003, Train_Loss: [0.7052, 0.6974]
Val_Loss: 0.691642, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #004, Train_Loss: [0.6997, 0.6918]
Val_Loss: 0.691198, Val_Acc: 0.833333
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #005, Train_Loss: [0.6912, 0.6976]
Val_Loss: 0.690674, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #006, Train_Loss: [0.6835, 0.6887]
Val_Loss: 0.689827, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #007, Train_Loss: [0.6780, 0.6710]
Val_Loss: 0.689163, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #008, Train_Loss: [0.6720, 0.6487]
Val_Loss: 0.689553, Val_Acc: 0.500000

Epoch #009, Train_Loss: [0.6527, 0.6804]
Val_Loss: 0.692146, Val_Acc: 0.500000

Epoch #010, Train_Loss: [0.6514, 0.5939]
Val_Loss: 0.699511, Val_Acc: 0.500000

Epoch #011, Train_Loss: [0.6259, 0.6538]
Val_Loss: 0.714716, Val_Acc: 0.500000

Epoch #012, Train_Loss: [0.6266, 0.5959]
Val_Loss: 0.737205, Val_Acc: 0.500000

Epoch #013, Train_Loss: [0.6206, 0.6011]
Val_Loss: 0.761376, Val_Acc: 0.500000

Epoch #014, Train_Loss: [0.6091, 0.5978]
Val_Loss: 0.778425, Val_Acc: 0.500000

Epoch #015, Train_Loss: [0.6509, 0.5289]
Val_Loss: 0.779322, Val_Acc: 0.500000

Epoch #016, Train_Loss: [0.6160, 0.6504]
Val_Loss: 0.767371, Val_Acc: 0.500000

Epoch #017, Train_Loss: [0.5914, 0.6959]
Val_Loss: 0.745350, Val_Acc: 0.500000

Epoch #018, Train_Loss: [0.5841, 0.7625]
Val_Loss: 0.722996, Val_Acc: 0.500000

Epoch #019, Train_Loss: [0.6172, 0.5607]
Val_Loss: 0.707338, Val_Acc: 0.500000

Epoch #020, Train_Loss: [0.5984, 0.6571]
Val_Loss: 0.699699, Val_Acc: 0.500000

Epoch #021, Train_Loss: [0.6114, 0.6108]
Val_Loss: 0.695509, Val_Acc: 0.500000

Epoch #022, Train_Loss: [0.6182, 0.5680]
Val_Loss: 0.694859, Val_Acc: 0.500000

Epoch #023, Train_Loss: [0.6018, 0.6452]
Val_Loss: 0.697069, Val_Acc: 0.500000

Epoch #024, Train_Loss: [0.6150, 0.4983]
Val_Loss: 0.703163, Val_Acc: 0.500000

Epoch #025, Train_Loss: [0.5985, 0.6639]
Val_Loss: 0.713044, Val_Acc: 0.500000

Epoch #026, Train_Loss: [0.5613, 0.8743]
Val_Loss: 0.715851, Val_Acc: 0.500000

Epoch #027, Train_Loss: [0.5924, 0.6299]
Val_Loss: 0.709777, Val_Acc: 0.500000

Epoch #028, Train_Loss: [0.6120, 0.5502]
Val_Loss: 0.705439, Val_Acc: 0.500000

Epoch #029, Train_Loss: [0.5855, 0.7060]
Val_Loss: 0.701141, Val_Acc: 0.500000

Epoch #030, Train_Loss: [0.6012, 0.5921]
Val_Loss: 0.696363, Val_Acc: 0.500000

Epoch #031, Train_Loss: [0.5877, 0.6309]
Val_Loss: 0.693069, Val_Acc: 0.500000

Epoch #032, Train_Loss: [0.5875, 0.6051]
Val_Loss: 0.690897, Val_Acc: 0.500000

Epoch #033, Train_Loss: [0.6132, 0.5044]
Val_Loss: 0.692353, Val_Acc: 0.500000

Epoch #034, Train_Loss: [0.6068, 0.5045]
Val_Loss: 0.699546, Val_Acc: 0.500000

Epoch #035, Train_Loss: [0.6009, 0.5262]
Val_Loss: 0.709594, Val_Acc: 0.500000

Epoch #036, Train_Loss: [0.5842, 0.5918]
Val_Loss: 0.717285, Val_Acc: 0.500000

Epoch #037, Train_Loss: [0.5753, 0.7135]
Val_Loss: 0.712066, Val_Acc: 0.500000

Epoch #038, Train_Loss: [0.5701, 0.6847]
Val_Loss: 0.693225, Val_Acc: 0.500000

Epoch #039, Train_Loss: [0.5695, 0.7072]
Val_Loss: 0.672669, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #040, Train_Loss: [0.5782, 0.5934]
Val_Loss: 0.661146, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #041, Train_Loss: [0.5983, 0.5193]
Val_Loss: 0.656412, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #042, Train_Loss: [0.5860, 0.6153]
Val_Loss: 0.654968, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #043, Train_Loss: [0.5809, 0.6099]
Val_Loss: 0.654764, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #044, Train_Loss: [0.5709, 0.6265]
Val_Loss: 0.654838, Val_Acc: 0.500000

Epoch #045, Train_Loss: [0.5767, 0.5472]
Val_Loss: 0.655235, Val_Acc: 0.500000

Epoch #046, Train_Loss: [0.5966, 0.4556]
Val_Loss: 0.658596, Val_Acc: 0.500000

Epoch #047, Train_Loss: [0.5683, 0.6156]
Val_Loss: 0.660818, Val_Acc: 0.500000

Epoch #048, Train_Loss: [0.5656, 0.5180]
Val_Loss: 0.654307, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #049, Train_Loss: [0.5519, 0.6594]
Val_Loss: 0.639594, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #050, Train_Loss: [0.5643, 0.5193]
Val_Loss: 0.624152, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #051, Train_Loss: [0.5274, 0.6571]
Val_Loss: 0.615434, Val_Acc: 0.500000
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #052, Train_Loss: [0.5438, 0.6203]
Val_Loss: 0.608699, Val_Acc: 0.555556
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #053, Train_Loss: [0.5601, 0.5402]
Val_Loss: 0.604131, Val_Acc: 0.555556
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #054, Train_Loss: [0.5635, 0.5386]
Val_Loss: 0.602583, Val_Acc: 0.555556
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #055, Train_Loss: [0.5431, 0.5924]
Val_Loss: 0.602038, Val_Acc: 0.555556
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #056, Train_Loss: [0.5530, 0.5233]
Val_Loss: 0.598867, Val_Acc: 0.555556
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #057, Train_Loss: [0.5334, 0.5673]
Val_Loss: 0.593188, Val_Acc: 0.555556
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #058, Train_Loss: [0.5362, 0.5911]
Val_Loss: 0.583927, Val_Acc: 0.611111
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #059, Train_Loss: [0.5307, 0.5224]
Val_Loss: 0.578549, Val_Acc: 0.611111
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #060, Train_Loss: [0.5491, 0.4555]
Val_Loss: 0.575788, Val_Acc: 0.666667
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #061, Train_Loss: [0.5199, 0.5776]
Val_Loss: 0.576509, Val_Acc: 0.666667

Epoch #062, Train_Loss: [0.5162, 0.6179]
Val_Loss: 0.577739, Val_Acc: 0.666667

Epoch #063, Train_Loss: [0.5280, 0.5811]
Val_Loss: 0.574377, Val_Acc: 0.666667
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #064, Train_Loss: [0.5252, 0.4636]
Val_Loss: 0.572447, Val_Acc: 0.722222
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #065, Train_Loss: [0.5259, 0.5028]
Val_Loss: 0.573749, Val_Acc: 0.722222

Epoch #066, Train_Loss: [0.5049, 0.6463]
Val_Loss: 0.569125, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #067, Train_Loss: [0.5355, 0.4342]
Val_Loss: 0.562571, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #068, Train_Loss: [0.5228, 0.5268]
Val_Loss: 0.559944, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #069, Train_Loss: [0.5196, 0.5676]
Val_Loss: 0.557898, Val_Acc: 0.833333
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #070, Train_Loss: [0.5277, 0.5391]
Val_Loss: 0.558090, Val_Acc: 0.777778

Epoch #071, Train_Loss: [0.5442, 0.4125]
Val_Loss: 0.563232, Val_Acc: 0.833333

Epoch #072, Train_Loss: [0.5251, 0.4701]
Val_Loss: 0.571731, Val_Acc: 0.833333

Epoch #073, Train_Loss: [0.5220, 0.5353]
Val_Loss: 0.569308, Val_Acc: 0.777778

Epoch #074, Train_Loss: [0.5392, 0.4090]
Val_Loss: 0.559589, Val_Acc: 0.777778

Epoch #075, Train_Loss: [0.5110, 0.5140]
Val_Loss: 0.554230, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #076, Train_Loss: [0.4999, 0.5706]
Val_Loss: 0.552450, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #077, Train_Loss: [0.5213, 0.4774]
Val_Loss: 0.549781, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #078, Train_Loss: [0.5251, 0.4162]
Val_Loss: 0.549785, Val_Acc: 0.777778

Epoch #079, Train_Loss: [0.5106, 0.4380]
Val_Loss: 0.553068, Val_Acc: 0.777778

Epoch #080, Train_Loss: [0.4771, 0.6750]
Val_Loss: 0.550415, Val_Acc: 0.777778

Epoch #081, Train_Loss: [0.5155, 0.4644]
Val_Loss: 0.542898, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #082, Train_Loss: [0.5106, 0.4405]
Val_Loss: 0.539539, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #083, Train_Loss: [0.5033, 0.4707]
Val_Loss: 0.541941, Val_Acc: 0.777778

Epoch #084, Train_Loss: [0.5437, 0.3293]
Val_Loss: 0.547888, Val_Acc: 0.777778

Epoch #085, Train_Loss: [0.4798, 0.6943]
Val_Loss: 0.543227, Val_Acc: 0.777778

Epoch #086, Train_Loss: [0.5361, 0.3203]
Val_Loss: 0.532652, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #087, Train_Loss: [0.5091, 0.3621]
Val_Loss: 0.531788, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #088, Train_Loss: [0.4960, 0.5429]
Val_Loss: 0.532478, Val_Acc: 0.777778

Epoch #089, Train_Loss: [0.4619, 0.6511]
Val_Loss: 0.522212, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #090, Train_Loss: [0.4978, 0.5583]
Val_Loss: 0.512393, Val_Acc: 0.777778
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********

Epoch #091, Train_Loss: [0.5315, 0.4276]
Val_Loss: 0.516136, Val_Acc: 0.777778

Epoch #092, Train_Loss: [0.5251, 0.3977]
Val_Loss: 0.532669, Val_Acc: 0.777778

Epoch #093, Train_Loss: [0.4869, 0.5149]
Val_Loss: 0.554766, Val_Acc: 0.777778

Epoch #094, Train_Loss: [0.5259, 0.4008]
Val_Loss: 0.565628, Val_Acc: 0.777778

Epoch #095, Train_Loss: [0.5543, 0.3574]
Val_Loss: 0.562480, Val_Acc: 0.777778

Epoch #096, Train_Loss: [0.4985, 0.6236]
Val_Loss: 0.546841, Val_Acc: 0.777778

Epoch #097, Train_Loss: [0.5270, 0.4575]
Val_Loss: 0.528591, Val_Acc: 0.777778

Epoch #098, Train_Loss: [0.5242, 0.4015]
Val_Loss: 0.519952, Val_Acc: 0.777778

Epoch #099, Train_Loss: [0.4890, 0.4458]
Val_Loss: 0.517938, Val_Acc: 0.777778

Epoch #100, Train_Loss: [0.5013, 0.4423]
Val_Loss: 0.518714, Val_Acc: 0.777778

Epoch #101, Train_Loss: [0.4919, 0.6086]
Val_Loss: 0.521418, Val_Acc: 0.777778

Epoch #102, Train_Loss: [0.5046, 0.4439]
Val_Loss: 0.523739, Val_Acc: 0.777778

Epoch #103, Train_Loss: [0.4954, 0.4912]
Val_Loss: 0.523161, Val_Acc: 0.777778

Epoch #104, Train_Loss: [0.4930, 0.4717]
Val_Loss: 0.521201, Val_Acc: 0.777778

Epoch #105, Train_Loss: [0.4930, 0.4526]
Val_Loss: 0.519834, Val_Acc: 0.777778

Epoch #106, Train_Loss: [0.4839, 0.4284]
Val_Loss: 0.521064, Val_Acc: 0.777778

Epoch #107, Train_Loss: [0.4865, 0.3557]
Val_Loss: 0.525405, Val_Acc: 0.777778

Epoch #108, Train_Loss: [0.4917, 0.4210]
Val_Loss: 0.536153, Val_Acc: 0.777778

Epoch #109, Train_Loss: [0.5094, 0.3035]
Val_Loss: 0.551014, Val_Acc: 0.777778

Epoch #110, Train_Loss: [0.4806, 0.5583]
Val_Loss: 0.562413, Val_Acc: 0.777778

Epoch #111, Train_Loss: [0.5056, 0.3433]
Val_Loss: 0.565330, Val_Acc: 0.777778

Epoch #112, Train_Loss: [0.4477, 0.5333]
Val_Loss: 0.561715, Val_Acc: 0.777778

Epoch #113, Train_Loss: [0.5121, 0.3181]
Val_Loss: 0.551478, Val_Acc: 0.777778

Epoch #114, Train_Loss: [0.5148, 0.3497]
Val_Loss: 0.544566, Val_Acc: 0.777778

Epoch #115, Train_Loss: [0.4215, 0.7079]
Val_Loss: 0.538546, Val_Acc: 0.777778

Epoch #116, Train_Loss: [0.4946, 0.4180]
Val_Loss: 0.534990, Val_Acc: 0.777778

Epoch #117, Train_Loss: [0.4471, 0.5374]
Val_Loss: 0.533049, Val_Acc: 0.777778

Epoch #118, Train_Loss: [0.4747, 0.4540]
Val_Loss: 0.530005, Val_Acc: 0.777778

Epoch #119, Train_Loss: [0.4844, 0.4808]
Val_Loss: 0.538531, Val_Acc: 0.777778

Epoch #120, Train_Loss: [0.4809, 0.3821]
Val_Loss: 0.550307, Val_Acc: 0.777778

Epoch #121, Train_Loss: [0.4971, 0.4238]
Val_Loss: 0.557201, Val_Acc: 0.777778

Epoch #122, Train_Loss: [0.5002, 0.4162]
Val_Loss: 0.555355, Val_Acc: 0.777778

Epoch #123, Train_Loss: [0.4775, 0.4352]
Val_Loss: 0.546742, Val_Acc: 0.777778

Epoch #124, Train_Loss: [0.4701, 0.6874]
Val_Loss: 0.533681, Val_Acc: 0.777778

Epoch #125, Train_Loss: [0.4425, 0.5665]
Val_Loss: 0.521146, Val_Acc: 0.777778

Epoch #126, Train_Loss: [0.4377, 0.6869]
Val_Loss: 0.516601, Val_Acc: 0.777778

Epoch #127, Train_Loss: [0.4820, 0.5340]
Val_Loss: 0.518132, Val_Acc: 0.777778

Epoch #128, Train_Loss: [0.4852, 0.4745]
Val_Loss: 0.527564, Val_Acc: 0.777778

Epoch #129, Train_Loss: [0.4672, 0.4950]
Val_Loss: 0.543704, Val_Acc: 0.777778

Epoch #130, Train_Loss: [0.4457, 0.6555]
Val_Loss: 0.554250, Val_Acc: 0.777778

Epoch #131, Train_Loss: [0.4829, 0.4734]
Val_Loss: 0.552938, Val_Acc: 0.777778

********** TEST START **********
Reload Best Model
The current best model is saved in: ******** outputs/MUTAG_Glo/model.pth *********
TEST :: Test_Acc: 0.800000
