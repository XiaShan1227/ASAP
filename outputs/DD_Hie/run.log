+-----------------+-------------------------+
|    Parameter    |          Value          |
+=================+=========================+
| Batch size      | 128                     |
+-----------------+-------------------------+
| Dataset         | DD                      |
+-----------------+-------------------------+
| Dropout ratio   | 0.5                     |
+-----------------+-------------------------+
| Epochs          | 10000                   |
+-----------------+-------------------------+
| Exp name        | DD_Hie                  |
+-----------------+-------------------------+
| Gpu index       | 0                       |
+-----------------+-------------------------+
| Hid             | 128                     |
+-----------------+-------------------------+
| Lr              | 0.0005                  |
+-----------------+-------------------------+
| Model           | ASAPooling_Hierarchical |
+-----------------+-------------------------+
| Patience        | 40                      |
+-----------------+-------------------------+
| Pooling ratio   | 0.5                     |
+-----------------+-------------------------+
| Seed            | 16                      |
+-----------------+-------------------------+
| Test batch size | 1                       |
+-----------------+-------------------------+
| Weight decay    | 0.0001                  |
+-----------------+-------------------------+
Using GPU: 0
ASAPooling_Hierarchical(
  (conv1): GCNConv(89, 128)
  (conv2): GCNConv(128, 128)
  (conv3): GCNConv(128, 128)
  (pool): ASAPooling(128, ratio=0.5)
  (lin1): Linear(in_features=256, out_features=128, bias=True)
  (lin2): Linear(in_features=128, out_features=64, bias=True)
  (classifier): Linear(in_features=64, out_features=2, bias=True)
)
Model Parameter: 119494
Using Adam

Epoch #000, Train_Loss: [0.6965, 0.6950, 0.6932, 0.6914, 0.6918, 0.6881, 0.6874, 0.6870]
Val_Loss: 0.691048, Val_Acc: 0.529915
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #001, Train_Loss: [0.6852, 0.6864, 0.6851, 0.6780, 0.6837, 0.6840, 0.6801, 0.6714]
Val_Loss: 0.690008, Val_Acc: 0.529915
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #002, Train_Loss: [0.6756, 0.6721, 0.6774, 0.6786, 0.6691, 0.6694, 0.6766, 0.6819]
Val_Loss: 0.694896, Val_Acc: 0.529915

Epoch #003, Train_Loss: [0.6815, 0.6678, 0.6664, 0.6640, 0.6779, 0.6573, 0.6568, 0.7022]
Val_Loss: 0.702747, Val_Acc: 0.529915

Epoch #004, Train_Loss: [0.6889, 0.6994, 0.6468, 0.6762, 0.6639, 0.6619, 0.6454, 0.6678]
Val_Loss: 0.696719, Val_Acc: 0.529915

Epoch #005, Train_Loss: [0.6542, 0.6814, 0.6608, 0.6905, 0.6335, 0.6523, 0.7054, 0.6278]
Val_Loss: 0.697972, Val_Acc: 0.529915

Epoch #006, Train_Loss: [0.6616, 0.6269, 0.6559, 0.6477, 0.7041, 0.7053, 0.6257, 0.7079]
Val_Loss: 0.700279, Val_Acc: 0.529915

Epoch #007, Train_Loss: [0.6550, 0.6718, 0.6425, 0.6463, 0.6609, 0.6846, 0.6812, 0.6522]
Val_Loss: 0.695682, Val_Acc: 0.529915

Epoch #008, Train_Loss: [0.6568, 0.6644, 0.6631, 0.6774, 0.6579, 0.6733, 0.6533, 0.6535]
Val_Loss: 0.693838, Val_Acc: 0.529915

Epoch #009, Train_Loss: [0.6205, 0.6656, 0.6732, 0.6379, 0.6971, 0.6372, 0.6952, 0.6576]
Val_Loss: 0.696736, Val_Acc: 0.529915

Epoch #010, Train_Loss: [0.6589, 0.6312, 0.6497, 0.6682, 0.6479, 0.6847, 0.6814, 0.6258]
Val_Loss: 0.694509, Val_Acc: 0.529915

Epoch #011, Train_Loss: [0.6518, 0.6820, 0.6432, 0.6652, 0.6436, 0.6660, 0.6397, 0.6932]
Val_Loss: 0.692493, Val_Acc: 0.529915

Epoch #012, Train_Loss: [0.6571, 0.6634, 0.6453, 0.6506, 0.7145, 0.6520, 0.6274, 0.6387]
Val_Loss: 0.688193, Val_Acc: 0.529915
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #013, Train_Loss: [0.6715, 0.6633, 0.6492, 0.6151, 0.6260, 0.7070, 0.6406, 0.6605]
Val_Loss: 0.690973, Val_Acc: 0.529915

Epoch #014, Train_Loss: [0.6641, 0.6179, 0.6541, 0.6532, 0.6136, 0.6828, 0.6609, 0.6114]
Val_Loss: 0.685632, Val_Acc: 0.529915
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #015, Train_Loss: [0.6559, 0.6468, 0.6181, 0.6729, 0.6095, 0.6114, 0.6520, 0.7411]
Val_Loss: 0.684543, Val_Acc: 0.529915
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #016, Train_Loss: [0.6818, 0.6487, 0.5967, 0.6310, 0.6417, 0.6785, 0.6185, 0.6300]
Val_Loss: 0.676210, Val_Acc: 0.538462
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #017, Train_Loss: [0.6275, 0.6478, 0.6204, 0.6389, 0.6714, 0.6309, 0.6138, 0.6195]
Val_Loss: 0.673632, Val_Acc: 0.538462
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #018, Train_Loss: [0.5922, 0.6528, 0.6134, 0.5860, 0.6317, 0.5859, 0.6909, 0.6055]
Val_Loss: 0.660952, Val_Acc: 0.555556
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #019, Train_Loss: [0.6193, 0.6044, 0.6117, 0.6285, 0.5617, 0.6549, 0.6022, 0.7321]
Val_Loss: 0.654948, Val_Acc: 0.598291
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #020, Train_Loss: [0.6181, 0.6459, 0.6099, 0.6227, 0.5936, 0.5835, 0.6038, 0.6449]
Val_Loss: 0.668274, Val_Acc: 0.572650

Epoch #021, Train_Loss: [0.6290, 0.6054, 0.5571, 0.6035, 0.6039, 0.6123, 0.6080, 0.5220]
Val_Loss: 0.648908, Val_Acc: 0.632479
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #022, Train_Loss: [0.6007, 0.5685, 0.5636, 0.6635, 0.5404, 0.5661, 0.6201, 0.5485]
Val_Loss: 0.632994, Val_Acc: 0.692308
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #023, Train_Loss: [0.5523, 0.6266, 0.5555, 0.5174, 0.5828, 0.5872, 0.5550, 0.5713]
Val_Loss: 0.633386, Val_Acc: 0.675214

Epoch #024, Train_Loss: [0.5903, 0.5860, 0.5661, 0.5744, 0.5481, 0.5657, 0.5219, 0.6085]
Val_Loss: 0.685325, Val_Acc: 0.641026

Epoch #025, Train_Loss: [0.5592, 0.5492, 0.5147, 0.5212, 0.5572, 0.5580, 0.5614, 0.5980]
Val_Loss: 0.621037, Val_Acc: 0.683761
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #026, Train_Loss: [0.5216, 0.5573, 0.5178, 0.5890, 0.5007, 0.5701, 0.5141, 0.4586]
Val_Loss: 0.616777, Val_Acc: 0.700855
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #027, Train_Loss: [0.4723, 0.5639, 0.5452, 0.5671, 0.5240, 0.5185, 0.5439, 0.5079]
Val_Loss: 0.605723, Val_Acc: 0.735043
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #028, Train_Loss: [0.5225, 0.5431, 0.4887, 0.4645, 0.5508, 0.5644, 0.4690, 0.5291]
Val_Loss: 0.604937, Val_Acc: 0.700855
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #029, Train_Loss: [0.5460, 0.5370, 0.4432, 0.5550, 0.4794, 0.6080, 0.5332, 0.5712]
Val_Loss: 0.587901, Val_Acc: 0.709402
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #030, Train_Loss: [0.5540, 0.5434, 0.4888, 0.4891, 0.5346, 0.4887, 0.4991, 0.4638]
Val_Loss: 0.577218, Val_Acc: 0.726496
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #031, Train_Loss: [0.4751, 0.5157, 0.5082, 0.4871, 0.5477, 0.4719, 0.4956, 0.6891]
Val_Loss: 0.573346, Val_Acc: 0.717949
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #032, Train_Loss: [0.5247, 0.4981, 0.5783, 0.5230, 0.5131, 0.4830, 0.5053, 0.5173]
Val_Loss: 0.712662, Val_Acc: 0.641026

Epoch #033, Train_Loss: [0.4759, 0.5493, 0.4736, 0.5169, 0.5524, 0.4939, 0.5549, 0.5395]
Val_Loss: 0.574434, Val_Acc: 0.735043

Epoch #034, Train_Loss: [0.5016, 0.5030, 0.4535, 0.5399, 0.4751, 0.4391, 0.4880, 0.4662]
Val_Loss: 0.571951, Val_Acc: 0.717949
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #035, Train_Loss: [0.4772, 0.4855, 0.4957, 0.4831, 0.5296, 0.4760, 0.4003, 0.4169]
Val_Loss: 0.595961, Val_Acc: 0.709402

Epoch #036, Train_Loss: [0.4656, 0.4116, 0.5389, 0.4983, 0.4559, 0.4604, 0.4459, 0.5330]
Val_Loss: 0.566138, Val_Acc: 0.717949
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #037, Train_Loss: [0.4853, 0.4025, 0.4619, 0.4745, 0.4501, 0.4360, 0.4577, 0.4396]
Val_Loss: 0.584676, Val_Acc: 0.735043

Epoch #038, Train_Loss: [0.5689, 0.4672, 0.4370, 0.4675, 0.4552, 0.3544, 0.4478, 0.4727]
Val_Loss: 0.593334, Val_Acc: 0.717949

Epoch #039, Train_Loss: [0.4573, 0.5042, 0.4470, 0.4356, 0.4191, 0.4119, 0.4040, 0.6481]
Val_Loss: 0.578848, Val_Acc: 0.735043

Epoch #040, Train_Loss: [0.4444, 0.4562, 0.4413, 0.4226, 0.4039, 0.4585, 0.4331, 0.4805]
Val_Loss: 0.539907, Val_Acc: 0.752137
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********

Epoch #041, Train_Loss: [0.4655, 0.4338, 0.4530, 0.4165, 0.4576, 0.4404, 0.3632, 0.4620]
Val_Loss: 0.544979, Val_Acc: 0.743590

Epoch #042, Train_Loss: [0.4776, 0.4927, 0.4556, 0.4558, 0.4125, 0.3770, 0.3513, 0.3607]
Val_Loss: 0.591862, Val_Acc: 0.726496

Epoch #043, Train_Loss: [0.4095, 0.4384, 0.4044, 0.4615, 0.4470, 0.4136, 0.3817, 0.5753]
Val_Loss: 0.575124, Val_Acc: 0.735043

Epoch #044, Train_Loss: [0.3993, 0.3926, 0.4136, 0.4169, 0.4823, 0.4365, 0.4275, 0.3650]
Val_Loss: 0.598698, Val_Acc: 0.717949

Epoch #045, Train_Loss: [0.4481, 0.4876, 0.3770, 0.4627, 0.4718, 0.4173, 0.3782, 0.4255]
Val_Loss: 0.652537, Val_Acc: 0.692308

Epoch #046, Train_Loss: [0.5297, 0.3247, 0.4983, 0.3757, 0.3548, 0.4841, 0.3799, 0.5123]
Val_Loss: 0.572417, Val_Acc: 0.760684

Epoch #047, Train_Loss: [0.4305, 0.4246, 0.3875, 0.4551, 0.4523, 0.3793, 0.3637, 0.3512]
Val_Loss: 0.564512, Val_Acc: 0.752137

Epoch #048, Train_Loss: [0.4387, 0.4019, 0.4409, 0.3741, 0.3796, 0.3737, 0.3189, 0.4803]
Val_Loss: 0.541865, Val_Acc: 0.726496

Epoch #049, Train_Loss: [0.3754, 0.4288, 0.3884, 0.4396, 0.3373, 0.4201, 0.4133, 0.4219]
Val_Loss: 0.606348, Val_Acc: 0.752137

Epoch #050, Train_Loss: [0.3880, 0.3515, 0.4601, 0.4474, 0.4277, 0.4048, 0.4613, 0.4264]
Val_Loss: 0.599177, Val_Acc: 0.735043

Epoch #051, Train_Loss: [0.3929, 0.4177, 0.3857, 0.4518, 0.4098, 0.4459, 0.3977, 0.3539]
Val_Loss: 0.587958, Val_Acc: 0.752137

Epoch #052, Train_Loss: [0.2835, 0.4185, 0.3826, 0.4377, 0.4159, 0.3222, 0.5036, 0.3066]
Val_Loss: 0.579798, Val_Acc: 0.760684

Epoch #053, Train_Loss: [0.4223, 0.3497, 0.4061, 0.4425, 0.3154, 0.4251, 0.3768, 0.4562]
Val_Loss: 0.568159, Val_Acc: 0.769231

Epoch #054, Train_Loss: [0.3546, 0.4150, 0.3571, 0.3916, 0.4147, 0.3937, 0.3721, 0.3721]
Val_Loss: 0.565293, Val_Acc: 0.735043

Epoch #055, Train_Loss: [0.5518, 0.5023, 0.3576, 0.3914, 0.3688, 0.4084, 0.4692, 0.3657]
Val_Loss: 0.541482, Val_Acc: 0.769231

Epoch #056, Train_Loss: [0.4320, 0.4239, 0.4144, 0.4092, 0.4603, 0.4714, 0.4463, 0.5319]
Val_Loss: 0.568927, Val_Acc: 0.743590

Epoch #057, Train_Loss: [0.3771, 0.3677, 0.4971, 0.3907, 0.3993, 0.4169, 0.4605, 0.5233]
Val_Loss: 0.609020, Val_Acc: 0.700855

Epoch #058, Train_Loss: [0.4431, 0.3163, 0.4058, 0.3658, 0.4751, 0.3967, 0.3335, 0.4577]
Val_Loss: 0.572155, Val_Acc: 0.743590

Epoch #059, Train_Loss: [0.4978, 0.3702, 0.3389, 0.3450, 0.3047, 0.4413, 0.4282, 0.3206]
Val_Loss: 0.546362, Val_Acc: 0.735043

Epoch #060, Train_Loss: [0.3913, 0.3390, 0.3163, 0.4236, 0.3751, 0.4193, 0.3350, 0.2889]
Val_Loss: 0.553814, Val_Acc: 0.726496

Epoch #061, Train_Loss: [0.3753, 0.3367, 0.3048, 0.3932, 0.3805, 0.4668, 0.3512, 0.2610]
Val_Loss: 0.565933, Val_Acc: 0.760684

Epoch #062, Train_Loss: [0.3735, 0.3687, 0.3773, 0.5163, 0.3976, 0.3497, 0.2587, 0.4766]
Val_Loss: 0.609721, Val_Acc: 0.743590

Epoch #063, Train_Loss: [0.3768, 0.3785, 0.3319, 0.3105, 0.4340, 0.3487, 0.3781, 0.3866]
Val_Loss: 0.609484, Val_Acc: 0.743590

Epoch #064, Train_Loss: [0.4742, 0.3463, 0.3701, 0.3960, 0.3467, 0.3863, 0.4044, 0.3617]
Val_Loss: 0.631702, Val_Acc: 0.717949

Epoch #065, Train_Loss: [0.3805, 0.3690, 0.3590, 0.3128, 0.3374, 0.4769, 0.3122, 0.5250]
Val_Loss: 0.578895, Val_Acc: 0.760684

Epoch #066, Train_Loss: [0.3718, 0.3293, 0.2638, 0.4304, 0.3620, 0.3947, 0.4286, 0.4431]
Val_Loss: 0.543358, Val_Acc: 0.726496

Epoch #067, Train_Loss: [0.3355, 0.4094, 0.3892, 0.3449, 0.3136, 0.3976, 0.4338, 0.3075]
Val_Loss: 0.581404, Val_Acc: 0.743590

Epoch #068, Train_Loss: [0.3288, 0.3437, 0.3871, 0.3863, 0.3303, 0.2940, 0.4061, 0.5403]
Val_Loss: 0.544757, Val_Acc: 0.735043

Epoch #069, Train_Loss: [0.4026, 0.3569, 0.3748, 0.3790, 0.4426, 0.3648, 0.3886, 0.3037]
Val_Loss: 0.572801, Val_Acc: 0.760684

Epoch #070, Train_Loss: [0.3789, 0.3760, 0.3378, 0.3458, 0.2897, 0.3295, 0.3632, 0.4192]
Val_Loss: 0.548577, Val_Acc: 0.726496

Epoch #071, Train_Loss: [0.3700, 0.4191, 0.3244, 0.3580, 0.3381, 0.2864, 0.3997, 0.4096]
Val_Loss: 0.547171, Val_Acc: 0.717949

Epoch #072, Train_Loss: [0.4330, 0.3955, 0.3034, 0.3758, 0.3649, 0.3047, 0.2692, 0.3022]
Val_Loss: 0.565997, Val_Acc: 0.743590

Epoch #073, Train_Loss: [0.3549, 0.3028, 0.3818, 0.2777, 0.2803, 0.3759, 0.3472, 0.3081]
Val_Loss: 0.558694, Val_Acc: 0.726496

Epoch #074, Train_Loss: [0.3597, 0.3610, 0.3184, 0.3823, 0.2946, 0.4170, 0.4839, 0.2580]
Val_Loss: 0.552363, Val_Acc: 0.726496

Epoch #075, Train_Loss: [0.3120, 0.3819, 0.3917, 0.3663, 0.2913, 0.3405, 0.3872, 0.5250]
Val_Loss: 0.575215, Val_Acc: 0.752137

Epoch #076, Train_Loss: [0.3696, 0.3120, 0.2956, 0.3349, 0.3599, 0.3625, 0.3355, 0.2871]
Val_Loss: 0.559277, Val_Acc: 0.735043

Epoch #077, Train_Loss: [0.2950, 0.3160, 0.4479, 0.2922, 0.3003, 0.3380, 0.3626, 0.3060]
Val_Loss: 0.583490, Val_Acc: 0.735043

Epoch #078, Train_Loss: [0.3105, 0.3636, 0.3691, 0.2737, 0.3017, 0.2733, 0.3738, 0.2787]
Val_Loss: 0.572085, Val_Acc: 0.735043

Epoch #079, Train_Loss: [0.3497, 0.3532, 0.3210, 0.2597, 0.2845, 0.4259, 0.3498, 0.3356]
Val_Loss: 0.580626, Val_Acc: 0.743590

Epoch #080, Train_Loss: [0.2982, 0.3191, 0.3476, 0.2873, 0.3950, 0.3338, 0.3264, 0.3456]
Val_Loss: 0.607029, Val_Acc: 0.760684

Epoch #081, Train_Loss: [0.3642, 0.3163, 0.3365, 0.2824, 0.3789, 0.4040, 0.3742, 0.2931]
Val_Loss: 0.577591, Val_Acc: 0.743590

********** TEST START **********
Reload Best Model
The current best model is saved in: ******** outputs/DD_Hie/model.pth *********
TEST :: Test_Acc: 0.655462
